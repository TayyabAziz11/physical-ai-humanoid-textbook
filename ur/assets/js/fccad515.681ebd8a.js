"use strict";(globalThis.webpackChunkphysical_ai_humanoid_textbook=globalThis.webpackChunkphysical_ai_humanoid_textbook||[]).push([[377],{2781:(n,e,i)=>{i.d(e,{A:()=>o});var s=i(6540);const r={container:"container_rfuW",buttonGroup:"buttonGroup_PlP3",actionButton:"actionButton_Uyam",banner:"banner_o2gZ",bannerIcon:"bannerIcon_OknK",bannerText:"bannerText_QUdu",closeBanner:"closeBanner_dCt7"};var t=i(4848);function o({className:n}){const[e,i]=(0,s.useState)(!1),[o,l]=(0,s.useState)(!1);return(0,t.jsxs)("div",{className:`${r.container} ${n||""}`,children:[(0,t.jsxs)("div",{className:r.buttonGroup,children:[(0,t.jsx)("button",{className:r.actionButton,onClick:()=>{i(!0),l(!1)},"aria-label":"Personalize chapter content",children:"\u2728 Personalize for Me"}),(0,t.jsx)("button",{className:r.actionButton,onClick:()=>{l(!0),i(!1)},"aria-label":"View chapter in Urdu",children:"\ud83c\udf10 View in Urdu"})]}),e&&(0,t.jsxs)("div",{className:r.banner,role:"alert",children:[(0,t.jsx)("span",{className:r.bannerIcon,children:"\u2139\ufe0f"}),(0,t.jsx)("span",{className:r.bannerText,children:"Personalization coming soon \u2013 AI will adapt this chapter to your learning style and background"}),(0,t.jsx)("button",{className:r.closeBanner,onClick:()=>i(!1),"aria-label":"Close banner",children:"\u2715"})]}),o&&(0,t.jsxs)("div",{className:r.banner,role:"alert",children:[(0,t.jsx)("span",{className:r.bannerIcon,children:"\u2139\ufe0f"}),(0,t.jsx)("span",{className:r.bannerText,children:"Urdu translation coming soon \u2013 Full textbook will be available in \u0627\u0631\u062f\u0648"}),(0,t.jsx)("button",{className:r.closeBanner,onClick:()=>l(!1),"aria-label":"Close banner",children:"\u2715"})]})]})}},2830:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>l,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"module-4-vision-language-action/chapter-1-vla-intro","title":"Chapter 1 - Introduction to VLA","description":"\u062a\u0639\u0627\u0631\u0641: AI \u0627\u0648\u0631 Robotics \u06a9\u0627 \u0633\u0646\u06af\u0645","source":"@site/i18n/ur/docusaurus-plugin-content-docs/current/module-4-vision-language-action/chapter-1-vla-intro.mdx","sourceDirName":"module-4-vision-language-action","slug":"/module-4-vision-language-action/chapter-1-vla-intro","permalink":"/physical-ai-humanoid-textbook/ur/docs/module-4-vision-language-action/chapter-1-vla-intro","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"chapter-1-vla-intro","title":"Chapter 1 - Introduction to VLA","sidebar_label":"Chapter 1: VLA Intro"},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/physical-ai-humanoid-textbook/ur/docs/module-4-vision-language-action/overview"}}');var r=i(4848),t=i(8453),o=i(2781);const l={id:"chapter-1-vla-intro",title:"Chapter 1 - Introduction to VLA",sidebar_label:"Chapter 1: VLA Intro"},a="\u0628\u0627\u0628 1: Vision-Language-Action \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641",c={},d=[{value:"\u062a\u0639\u0627\u0631\u0641: AI \u0627\u0648\u0631 Robotics \u06a9\u0627 \u0633\u0646\u06af\u0645",id:"\u062a\u0639\u0627\u0631\u0641-ai-\u0627\u0648\u0631-robotics-\u06a9\u0627-\u0633\u0646\u06af\u0645",level:2},{value:"VLA Models \u06a9\u06cc\u0627 \u06c1\u06cc\u06ba\u061f",id:"vla-models-\u06a9\u06cc\u0627-\u06c1\u06cc\u06ba",level:2},{value:"Traditional Pipeline (\u067e\u0631\u0627\u0646\u0627 \u0637\u0631\u06cc\u0642\u06c1)",id:"traditional-pipeline-\u067e\u0631\u0627\u0646\u0627-\u0637\u0631\u06cc\u0642\u06c1",level:3},{value:"VLA Pipeline (\u0646\u06cc\u0627 \u0637\u0631\u06cc\u0642\u06c1)",id:"vla-pipeline-\u0646\u06cc\u0627-\u0637\u0631\u06cc\u0642\u06c1",level:3},{value:"\u0627\u06c1\u0645 VLA Architectures",id:"\u0627\u06c1\u0645-vla-architectures",level:2},{value:"1. RT-1 (Robotics Transformer 1)",id:"1-rt-1-robotics-transformer-1",level:3},{value:"2. RT-2 (Robotics Transformer 2)",id:"2-rt-2-robotics-transformer-2",level:3},{value:"VLA Models \u06a9\u06cc\u0633\u06d2 \u06a9\u0627\u0645 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba: \u0642\u062f\u0645 \u0628\u06c1 \u0642\u062f\u0645",id:"vla-models-\u06a9\u06cc\u0633\u06d2-\u06a9\u0627\u0645-\u06a9\u0631\u062a\u06d2-\u06c1\u06cc\u06ba-\u0642\u062f\u0645-\u0628\u06c1-\u0642\u062f\u0645",level:2},{value:"\u0645\u062b\u0627\u0644 \u06a9\u0627 \u06a9\u0627\u0645: &quot;\u0633\u0631\u062e \u0645\u06af \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba&quot;",id:"\u0645\u062b\u0627\u0644-\u06a9\u0627-\u06a9\u0627\u0645-\u0633\u0631\u062e-\u0645\u06af-\u0627\u0679\u06be\u0627\u0626\u06cc\u06ba",level:3},{value:"VLA Models \u06a9\u06cc \u062a\u0631\u0628\u06cc\u062a: Imitation Learning",id:"vla-models-\u06a9\u06cc-\u062a\u0631\u0628\u06cc\u062a-imitation-learning",level:2},{value:"\u062a\u0631\u0628\u06cc\u062a\u06cc \u0639\u0645\u0644",id:"\u062a\u0631\u0628\u06cc\u062a\u06cc-\u0639\u0645\u0644",level:3},{value:"VLA \u062a\u0631\u0628\u06cc\u062a \u06a9\u06d2 \u0644\u06cc\u06d2 Datasets",id:"vla-\u062a\u0631\u0628\u06cc\u062a-\u06a9\u06d2-\u0644\u06cc\u06d2-datasets",level:3},{value:"VLA \u06a9\u0648 ROS 2 \u0633\u06d2 \u062c\u0648\u0691\u0646\u0627",id:"vla-\u06a9\u0648-ros-2-\u0633\u06d2-\u062c\u0648\u0691\u0646\u0627",level:2},{value:"\u0645\u062b\u0627\u0644: Robot \u067e\u0631 RT-2 \u062a\u0639\u06cc\u0646\u0627\u062a \u06a9\u0631\u0646\u0627",id:"\u0645\u062b\u0627\u0644-robot-\u067e\u0631-rt-2-\u062a\u0639\u06cc\u0646\u0627\u062a-\u06a9\u0631\u0646\u0627",level:3},{value:"\u0622\u0648\u0627\u0632 \u2192 \u0628\u0635\u0627\u0631\u062a \u2192 \u0639\u0645\u0644: \u0645\u06a9\u0645\u0644 \u0645\u062b\u0627\u0644",id:"\u0622\u0648\u0627\u0632--\u0628\u0635\u0627\u0631\u062a--\u0639\u0645\u0644-\u0645\u06a9\u0645\u0644-\u0645\u062b\u0627\u0644",level:2},{value:"System Architecture",id:"system-architecture",level:3},{value:"\u0645\u0631\u062d\u0644\u06c1 1: Whisper \u06a9\u06d2 \u0633\u0627\u062a\u06be Speech-to-Text",id:"\u0645\u0631\u062d\u0644\u06c1-1-whisper-\u06a9\u06d2-\u0633\u0627\u062a\u06be-speech-to-text",level:3},{value:"\u0645\u0631\u062d\u0644\u06c1 2: \u0645\u06a9\u0645\u0644 System \u0644\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba",id:"\u0645\u0631\u062d\u0644\u06c1-2-\u0645\u06a9\u0645\u0644-system-\u0644\u0627\u0646\u0686-\u06a9\u0631\u06cc\u06ba",level:3},{value:"\u0645\u0631\u062d\u0644\u06c1 3: \u0627\u0633 \u06a9\u06cc \u062c\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba",id:"\u0645\u0631\u062d\u0644\u06c1-3-\u0627\u0633-\u06a9\u06cc-\u062c\u0627\u0646\u0686-\u06a9\u0631\u06cc\u06ba",level:3},{value:"Capstone: \u062e\u0648\u062f\u06a9\u0627\u0631 Humanoid Assistant \u0628\u0646\u0627\u0646\u0627",id:"capstone-\u062e\u0648\u062f\u06a9\u0627\u0631-humanoid-assistant-\u0628\u0646\u0627\u0646\u0627",level:2},{value:"System \u06a9\u06cc \u0636\u0631\u0648\u0631\u06cc\u0627\u062a",id:"system-\u06a9\u06cc-\u0636\u0631\u0648\u0631\u06cc\u0627\u062a",level:3},{value:"Software Architecture",id:"software-architecture",level:3},{value:"Implementation Flow",id:"implementation-flow",level:3},{value:"\u062d\u0641\u0627\u0638\u062a \u0627\u0648\u0631 \u0627\u0646\u0633\u0627\u0646\u06cc \u062a\u0639\u0627\u0645\u0644",id:"\u062d\u0641\u0627\u0638\u062a-\u0627\u0648\u0631-\u0627\u0646\u0633\u0627\u0646\u06cc-\u062a\u0639\u0627\u0645\u0644",level:3},{value:"\u0627\u06c1\u0645 \u0646\u06a9\u0627\u062a",id:"\u0627\u06c1\u0645-\u0646\u06a9\u0627\u062a",level:2},{value:"\u06c1\u0627\u062a\u06be \u0633\u06d2 \u0639\u0645\u0644\u06cc \u0645\u0634\u0642",id:"\u06c1\u0627\u062a\u06be-\u0633\u06d2-\u0639\u0645\u0644\u06cc-\u0645\u0634\u0642",level:2},{value:"\u0648\u0631\u0632\u0634 1: VLA Inference \u06a9\u06cc \u0631\u0641\u062a\u0627\u0631 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba",id:"\u0648\u0631\u0632\u0634-1-vla-inference-\u06a9\u06cc-\u0631\u0641\u062a\u0627\u0631-\u06a9\u0627-\u062d\u0633\u0627\u0628-\u0644\u06af\u0627\u0626\u06cc\u06ba",level:3},{value:"\u0648\u0631\u0632\u0634 2: VLA \u062a\u0631\u0628\u06cc\u062a\u06cc Dataset \u0688\u06cc\u0632\u0627\u0626\u0646 \u06a9\u0631\u06cc\u06ba",id:"\u0648\u0631\u0632\u0634-2-vla-\u062a\u0631\u0628\u06cc\u062a\u06cc-dataset-\u0688\u06cc\u0632\u0627\u0626\u0646-\u06a9\u0631\u06cc\u06ba",level:3},{value:"\u0648\u0631\u0632\u0634 3: Hybrid Planning",id:"\u0648\u0631\u0632\u0634-3-hybrid-planning",level:3},{value:"\u0648\u0631\u0632\u0634 4: \u062d\u0641\u0627\u0638\u062a\u06cc \u0646\u0627\u06a9\u0627\u0645\u06cc \u06a9\u06d2 \u0637\u0631\u06cc\u0642\u06d2",id:"\u0648\u0631\u0632\u0634-4-\u062d\u0641\u0627\u0638\u062a\u06cc-\u0646\u0627\u06a9\u0627\u0645\u06cc-\u06a9\u06d2-\u0637\u0631\u06cc\u0642\u06d2",level:3},{value:"\u0639\u0627\u0645 \u063a\u0644\u0637\u06cc\u0627\u06ba \u062c\u0648 \u0627\u0628\u062a\u062f\u0627\u0626\u06cc \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba",id:"\u0639\u0627\u0645-\u063a\u0644\u0637\u06cc\u0627\u06ba-\u062c\u0648-\u0627\u0628\u062a\u062f\u0627\u0626\u06cc-\u06a9\u0631\u062a\u06d2-\u06c1\u06cc\u06ba",level:2},{value:"\u0622\u06af\u06d2 \u06a9\u06cc\u0627 \u06c1\u06d2\u061f",id:"\u0622\u06af\u06d2-\u06a9\u06cc\u0627-\u06c1\u06d2",level:2}];function h(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.header,{children:(0,r.jsx)(e.h1,{id:"\u0628\u0627\u0628-1-vision-language-action-\u06a9\u0627-\u062a\u0639\u0627\u0631\u0641",children:"\u0628\u0627\u0628 1: Vision-Language-Action \u06a9\u0627 \u062a\u0639\u0627\u0631\u0641"})}),"\n",(0,r.jsx)(o.A,{}),"\n",(0,r.jsx)(e.h2,{id:"\u062a\u0639\u0627\u0631\u0641-ai-\u0627\u0648\u0631-robotics-\u06a9\u0627-\u0633\u0646\u06af\u0645",children:"\u062a\u0639\u0627\u0631\u0641: AI \u0627\u0648\u0631 Robotics \u06a9\u0627 \u0633\u0646\u06af\u0645"}),"\n",(0,r.jsx)(e.p,{children:'\u062a\u0635\u0648\u0631 \u06a9\u0631\u06cc\u06ba \u06a9\u06c1 \u0622\u067e \u06c1\u06cc\u0648\u0645\u0646\u0627\u0626\u06cc\u0688 \u0631\u0648\u0628\u0648\u0679 \u0633\u06d2 \u06a9\u06c1\u062a\u06d2 \u06c1\u06cc\u06ba: "\u0628\u0631\u0627\u06c1 \u06a9\u0631\u0645 \u0628\u0627\u0648\u0631\u0686\u06cc \u062e\u0627\u0646\u06d2 \u06a9\u06d2 \u06a9\u0627\u0624\u0646\u0679\u0631 \u0633\u06d2 \u0633\u0631\u062e \u06a9\u067e \u0644\u06d2 \u0622\u0626\u06cc\u06ba\u06d4"'}),"\n",(0,r.jsx)(e.p,{children:"\u0627\u0633 \u0633\u0627\u062f\u06c1 \u062f\u0631\u062e\u0648\u0627\u0633\u062a \u06a9\u06d2 \u06a9\u0627\u0645 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2\u060c \u0631\u0648\u0628\u0648\u0679 \u06a9\u0648 \u0636\u0631\u0648\u0631\u062a \u06c1\u06d2:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u0632\u0628\u0627\u0646 \u0633\u0645\u062c\u06be\u0646\u0627"}),': "\u0628\u0627\u0648\u0631\u0686\u06cc \u062e\u0627\u0646\u06d2 \u06a9\u06d2 \u06a9\u0627\u0624\u0646\u0679\u0631 \u0633\u06d2 \u0633\u0631\u062e \u06a9\u067e \u0644\u06d2 \u0622\u0626\u06cc\u06ba" \u06a9\u0648 parse \u06a9\u0631\u0646\u0627']}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u062f\u0646\u06cc\u0627 \u062f\u06cc\u06a9\u06be\u0646\u0627"}),": \u0627\u0634\u06cc\u0627\u0621 \u06a9\u06cc \u0634\u0646\u0627\u062e\u062a\u060c \u062c\u06af\u06c1\u0648\u06ba \u0645\u06cc\u06ba navigate \u06a9\u0631\u0646\u0627\u060c \u0631\u06a9\u0627\u0648\u0679\u0648\u06ba \u0633\u06d2 \u0628\u0686\u0646\u0627"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u0639\u0645\u0644 \u06a9\u0631\u0646\u0627"}),": \u0631\u0627\u0633\u062a\u06d2 \u06a9\u06cc \u0645\u0646\u0635\u0648\u0628\u06c1 \u0628\u0646\u062f\u06cc\u060c \u06a9\u067e \u067e\u06a9\u0691\u0646\u0627\u060c \u0627\u0633\u06d2 \u0645\u062d\u0641\u0648\u0638 \u0637\u0631\u06cc\u0642\u06d2 \u0633\u06d2 \u0644\u06d2 \u062c\u0627\u0646\u0627"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"\u0631\u0648\u0627\u06cc\u062a\u06cc robotics \u0627\u0646 \u0635\u0644\u0627\u062d\u06cc\u062a\u0648\u06ba \u06a9\u0648 \u0622\u0632\u0627\u062f \u0646\u0638\u0627\u0645\u0648\u06ba \u0645\u06cc\u06ba \u0627\u0644\u06af \u06a9\u0631\u062a\u0627 \u06c1\u06d2:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u062a\u0642\u0631\u06cc\u0631 \u06a9\u06cc \u0634\u0646\u0627\u062e\u062a \u2192 \u0642\u062f\u0631\u062a\u06cc \u0632\u0628\u0627\u0646 \u06a9\u06cc \u067e\u0631\u0648\u0633\u06cc\u0633\u0646\u06af"}),"\n",(0,r.jsx)(e.li,{children:"\u06a9\u0645\u067e\u06cc\u0648\u0679\u0631 \u0648\u06cc\u0698\u0646 \u2192 \u0622\u0628\u062c\u06cc\u06a9\u0679 \u0688\u06cc\u0679\u06cc\u06a9\u0634\u0646"}),"\n",(0,r.jsx)(e.li,{children:"\u062d\u0631\u06a9\u062a \u06a9\u06cc \u0645\u0646\u0635\u0648\u0628\u06c1 \u0628\u0646\u062f\u06cc \u2192 \u06a9\u0646\u0679\u0631\u0648\u0644 \u0633\u0633\u0679\u0645"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"\u06c1\u0631 \u0646\u0638\u0627\u0645 \u0622\u0632\u0627\u062f\u0627\u0646\u06c1 \u0637\u0648\u0631 \u067e\u0631 \u0628\u0646\u0627\u06cc\u0627 \u0627\u0648\u0631 \u062a\u0631\u0628\u06cc\u062a \u06cc\u0627\u0641\u062a\u06c1 \u06c1\u0648\u062a\u0627 \u06c1\u06d2\u060c \u067e\u06be\u0631 \u0646\u0627\u0632\u06a9 integration code \u06a9\u06d2 \u0633\u0627\u062a\u06be \u062c\u0648\u0691\u0627 \u062c\u0627\u062a\u0627 \u06c1\u06d2\u06d4"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Vision-Language-Action (VLA)"})," models \u0627\u06cc\u06a9 paradigm shift \u06a9\u06cc \u0646\u0645\u0627\u0626\u0646\u062f\u06af\u06cc \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba: \u0627\u06cc\u06a9 ",(0,r.jsx)(e.strong,{children:"\u0648\u0627\u062d\u062f neural network"})," \u062c\u0648 \u0628\u0631\u0627\u06c1 \u0631\u0627\u0633\u062a pixels \u0627\u0648\u0631 text \u0633\u06d2 robot actions \u06a9\u06cc \u0637\u0631\u0641 map \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u06d4"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u06cc\u06c1 \u06a9\u06cc\u0648\u06ba \u0627\u06c1\u0645 \u06c1\u06d2:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"End-to-End Learning"}),": \u067e\u0648\u0631\u06cc pipeline \u06a9\u0648 \u0627\u06cc\u06a9 \u0633\u0627\u062a\u06be \u062a\u0631\u0628\u06cc\u062a \u062f\u06cc\u06ba\u060c \u0627\u0644\u06af \u062d\u0635\u0648\u06ba \u06a9\u0648 \u0646\u06c1\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Emergent Behaviors"}),": Model \u0648\u06c1 shortcuts \u0633\u06cc\u06a9\u06be\u062a\u0627 \u06c1\u06d2 \u062c\u0648 \u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u0646\u06d2 \u06a9\u0628\u06be\u06cc \u0648\u0627\u0636\u062d \u0637\u0648\u0631 \u067e\u0631 program \u0646\u06c1\u06cc\u06ba \u06a9\u06cc\u06d2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Data Efficiency"}),": robotics \u06a9\u06d2 \u0644\u06cc\u06d2 internet-scale language \u0627\u0648\u0631 vision data \u0633\u06d2 \u0641\u0627\u0626\u062f\u06c1 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Generalization"}),": \u0627\u06cc\u06a9 model \u0628\u06c1\u062a \u0633\u06d2 \u06a9\u0627\u0645\u0648\u06ba \u0627\u0648\u0631 \u0645\u0627\u062d\u0648\u0644 \u0645\u06cc\u06ba \u06a9\u0627\u0645 \u06a9\u0631\u062a\u0627 \u06c1\u06d2"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"\u0627\u0633 \u0628\u0627\u0628 \u0645\u06cc\u06ba\u060c \u0622\u067e \u0633\u06cc\u06a9\u06be\u06cc\u06ba \u06af\u06d2 \u06a9\u06c1 \u06a9\u06cc\u0633\u06d2 Google \u06a9\u06d2 RT-1 \u0627\u0648\u0631 RT-2 \u062c\u06cc\u0633\u06d2 VLA models robots \u06a9\u0648 scripted machines \u0633\u06d2 adaptive agents \u0645\u06cc\u06ba \u062a\u0628\u062f\u06cc\u0644 \u06a9\u0631 \u0631\u06c1\u06d2 \u06c1\u06cc\u06ba\u06d4"}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"vla-models-\u06a9\u06cc\u0627-\u06c1\u06cc\u06ba",children:"VLA Models \u06a9\u06cc\u0627 \u06c1\u06cc\u06ba\u061f"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Vision-Language-Action (VLA)"})," models neural networks \u06c1\u06cc\u06ba \u062c\u0648 ",(0,r.jsx)(e.strong,{children:"visual observations"})," (camera images) \u0627\u0648\u0631 ",(0,r.jsx)(e.strong,{children:"language instructions"})," (text commands) \u06a9\u0648 input \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 \u0644\u06cc\u062a\u06d2 \u06c1\u06cc\u06ba\u060c \u0627\u0648\u0631 ",(0,r.jsx)(e.strong,{children:"robot actions"})," (joint positions\u060c gripper states) output \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba\u06d4"]}),"\n",(0,r.jsx)(e.h3,{id:"traditional-pipeline-\u067e\u0631\u0627\u0646\u0627-\u0637\u0631\u06cc\u0642\u06c1",children:"Traditional Pipeline (\u067e\u0631\u0627\u0646\u0627 \u0637\u0631\u06cc\u0642\u06c1)"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:'User: "\u0633\u06cc\u0628 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"\n    \u2193\nSpeech-to-Text (Whisper) \u2192 "\u0633\u06cc\u0628 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"\n    \u2193\nNLP (GPT-4) \u2192 Intent: PICK_OBJECT, Target: "\u0633\u06cc\u0628"\n    \u2193\nObject Detection (YOLO) \u2192 Bounding box: [x=120, y=340, w=80, h=100]\n    \u2193\nMotion Planning (MoveIt) \u2192 Joint trajectory: [\u03b8\u2081, \u03b8\u2082, ..., \u03b8\u2087]\n    \u2193\nRobot \u062d\u0631\u06a9\u062a \u06a9\u0648 execute \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0633\u0627\u0626\u0644:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u06c1\u0631 \u062c\u0632\u0648 \u0622\u0632\u0627\u062f\u0627\u0646\u06c1 \u0637\u0648\u0631 \u067e\u0631 \u0646\u0627\u06a9\u0627\u0645 \u06c1\u0648\u062a\u0627 \u06c1\u06d2 (detection \u0686\u06be\u0648\u0679 \u062c\u0627\u062a\u0627 \u06c1\u06d2\u060c planner \u067e\u06be\u0646\u0633 \u062c\u0627\u062a\u0627 \u06c1\u06d2)"}),"\n",(0,r.jsx)(e.li,{children:"\u063a\u0644\u0637\u06cc\u0627\u06ba pipeline \u06a9\u06d2 \u0630\u0631\u06cc\u0639\u06d2 compound \u06c1\u0648\u062a\u06cc \u06c1\u06cc\u06ba"}),"\n",(0,r.jsx)(e.li,{children:"\u06a9\u0648\u0626\u06cc shared learning \u0646\u06c1\u06cc\u06ba\u2014vision planning \u0645\u06cc\u06ba \u0645\u062f\u062f \u0646\u06c1\u06cc\u06ba \u06a9\u0631\u062a\u0627\u060c \u0627\u0648\u0631 vice versa"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"vla-pipeline-\u0646\u06cc\u0627-\u0637\u0631\u06cc\u0642\u06c1",children:"VLA Pipeline (\u0646\u06cc\u0627 \u0637\u0631\u06cc\u0642\u06c1)"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:'User: "\u0633\u06cc\u0628 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"\n    \u2193\nVLA Model (RT-2)\n  Inputs: Camera image + "\u0633\u06cc\u0628 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"\n  Output: [Joint deltas: \u0394\u03b8\u2081, \u0394\u03b8\u2082, ..., \u0394\u03b8\u2087, gripper_open: False]\n    \u2193\nRobot \u0639\u0645\u0644 \u06a9\u0648 \u0628\u0631\u0627\u06c1 \u0631\u0627\u0633\u062a execute \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0641\u0648\u0627\u0626\u062f:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u0648\u0627\u062d\u062f model"})," \u067e\u0648\u0631\u06cc mapping \u0633\u06cc\u06a9\u06be\u062a\u0627 \u06c1\u06d2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"End-to-end optimization"})," \u062d\u062a\u0645\u06cc \u06a9\u0627\u0645 \u06a9\u06cc \u063a\u0644\u0637\u06cc \u06a9\u0648 \u06a9\u0645 \u0633\u06d2 \u06a9\u0645 \u06a9\u0631\u062a\u06cc \u06c1\u06d2\u060c \u062f\u0631\u0645\u06cc\u0627\u0646\u06cc metrics \u06a9\u0648 \u0646\u06c1\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Implicit reasoning"}),' \u0627\u0628\u06be\u0631\u062a\u0627 \u06c1\u06d2 (\u0645\u062b\u0644\u0627\u064b\u060c \u0648\u0627\u0636\u062d obstacle detection \u06a9\u06d2 \u0628\u063a\u06cc\u0631 "\u0631\u06a9\u0627\u0648\u0679 \u0633\u06d2 \u0628\u0686\u06cc\u06ba")']}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"\u0627\u06c1\u0645-vla-architectures",children:"\u0627\u06c1\u0645 VLA Architectures"}),"\n",(0,r.jsx)(e.h3,{id:"1-rt-1-robotics-transformer-1",children:"1. RT-1 (Robotics Transformer 1)"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Google Research \u06a9\u06cc \u0637\u0631\u0641 \u0633\u06d2 \u062c\u0627\u0631\u06cc (2022)"})}),"\n",(0,r.jsx)(e.p,{children:"RT-1 \u0627\u06cc\u06a9 transformer-based model \u06c1\u06d2 \u062c\u0648 \u062d\u0642\u06cc\u0642\u06cc \u0628\u0627\u0648\u0631\u0686\u06cc \u062e\u0627\u0646\u0648\u06ba \u0627\u0648\u0631 \u062f\u0641\u0627\u062a\u0631 \u0645\u06cc\u06ba \u0627\u06a9\u0679\u06be\u06d2 \u06a9\u06cc\u06d2 \u06af\u0626\u06d2 130,000 robot demonstrations \u067e\u0631 \u062a\u0631\u0628\u06cc\u062a \u06cc\u0627\u0641\u062a\u06c1 \u06c1\u06d2\u06d4"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0641\u0646 \u062a\u0639\u0645\u06cc\u0631:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:'\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Camera Images (6 views)             \u2502  \u2190 Visual input\n\u2502  [224x224x3 \u0641\u06cc camera]              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  EfficientNet \u2502  \u2190 Image encoder\n    \u2502  (pretrained) \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2193\n    [Visual tokens: 512-dim]\n            \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Language Instruction                \u2502  \u2190 Language input\n\u2502  "\u0646\u06cc\u0644\u0627 \u0628\u0644\u0627\u06a9 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  USE Encoder  \u2502  \u2190 Universal Sentence Encoder\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2193\n    [Language tokens: 512-dim]\n            \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Transformer Decoder    \u2502  \u2190 Attention mechanism\n    \u2502  (8 layers, 128 heads)  \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2193\n    [Action tokens: 11-dim]\n                \u2193\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502  Robot Actions (\u06c1\u0631 3 Hz)        \u2502\n    \u2502  [x, y, z, roll, pitch, yaw,     \u2502\n    \u2502   gripper, terminate]            \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u062a\u0631\u0628\u06cc\u062a\u06cc \u0688\u06cc\u0679\u0627:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"Robot manipulation \u06a9\u0627\u0645\u0648\u06ba \u06a9\u06cc 130,000 episodes"}),"\n",(0,r.jsx)(e.li,{children:'\u06a9\u0627\u0645: "X \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"\u060c "X \u06a9\u0648 Y \u0645\u06cc\u06ba \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u06cc\u06ba"\u060c "\u062f\u0631\u0627\u0632 \u06a9\u06be\u0648\u0644\u06cc\u06ba"\u060c "\u0688\u06be\u06a9\u0646 \u0628\u0646\u062f \u06a9\u0631\u06cc\u06ba"'}),"\n",(0,r.jsx)(e.li,{children:"Human teleoperation \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631 \u06a9\u06d2 \u062c\u0645\u0639 \u06a9\u06cc\u0627 \u06af\u06cc\u0627 (joystick control)"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Performance:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u062a\u0631\u0628\u06cc\u062a \u06cc\u0627\u0641\u062a\u06c1 \u06a9\u0627\u0645\u0648\u06ba \u067e\u0631 97% \u06a9\u0627\u0645\u06cc\u0627\u0628\u06cc"}),"\n",(0,r.jsx)(e.li,{children:"\u0646\u0626\u06cc \u0627\u0634\u06cc\u0627\u0621 \u067e\u0631 76% \u06a9\u0627\u0645\u06cc\u0627\u0628\u06cc (\u062a\u0631\u0628\u06cc\u062a \u06a9\u06d2 \u062f\u0648\u0631\u0627\u0646 \u0646\u06c1\u06cc\u06ba \u062f\u06cc\u06a9\u06be\u06cc\u06ba)"}),"\n",(0,r.jsx)(e.li,{children:"\u0648\u0627\u062d\u062f GPU \u067e\u0631 3 Hz (333 ms \u0641\u06cc action) \u067e\u0631 \u0686\u0644\u062a\u0627 \u06c1\u06d2"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"2-rt-2-robotics-transformer-2",children:"2. RT-2 (Robotics Transformer 2)"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Google Research \u06a9\u06cc \u0637\u0631\u0641 \u0633\u06d2 \u062c\u0627\u0631\u06cc (2023)"})}),"\n",(0,r.jsxs)(e.p,{children:["RT-2 ",(0,r.jsx)(e.strong,{children:"vision-language models (VLMs)"})," \u062c\u06cc\u0633\u06d2 PaLM-E \u0627\u0648\u0631 CLIP \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631 \u06a9\u06d2 RT-1 \u06a9\u0648 \u0628\u0691\u06be\u0627\u062a\u0627 \u06c1\u06d2\u060c \u062c\u0648 ",(0,r.jsx)(e.strong,{children:"internet-scale"})," image-text data \u067e\u0631 pretrained \u06c1\u06cc\u06ba\u06d4"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0627\u06c1\u0645 \u0628\u0635\u06cc\u0631\u062a:"})}),"\n",(0,r.jsx)(e.p,{children:"Internet data \u0645\u06cc\u06ba implicit physics \u0627\u0648\u0631 common-sense reasoning \u0634\u0627\u0645\u0644 \u06c1\u06d2:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:'"\u067e\u0627\u0646\u06cc \u0688\u0627\u0644\u0646\u0627" \u06a9\u06cc \u062a\u0635\u0627\u0648\u06cc\u0631 \u0645\u0627\u0626\u0639 \u06a9\u06cc dynamics \u0633\u06a9\u06be\u0627\u062a\u06cc \u06c1\u06cc\u06ba'}),"\n",(0,r.jsx)(e.li,{children:'"\u062c\u0627\u0631 \u06a9\u06be\u0648\u0644\u06cc\u06ba" captions twist motions \u0633\u06a9\u06be\u0627\u062a\u06d2 \u06c1\u06cc\u06ba'}),"\n",(0,r.jsx)(e.li,{children:'"\u06a9\u0631\u0633\u06cc \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u06cc\u06ba" \u062a\u0635\u0627\u0648\u06cc\u0631 \u0628\u0691\u06cc \u0627\u0634\u06cc\u0627\u0621 \u06a9\u06cc manipulation \u0633\u06a9\u06be\u0627\u062a\u06cc \u06c1\u06cc\u06ba'}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:["RT-2 \u0627\u0646 VLMs \u06a9\u0648 robot data \u067e\u0631 ",(0,r.jsx)(e.strong,{children:"fine-tune"})," \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u060c web knowledge \u06a9\u0648 robotics \u0645\u06cc\u06ba \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u06d4"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0641\u0646 \u062a\u0639\u0645\u06cc\u0631:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:'Pretrained VLM (PaLM-E / CLIP)\n    \u2193 Robot data \u067e\u0631 Fine-tune\nRT-2 Model\n    \u2193 Input: Image + "\u06a9\u067e \u0645\u06cc\u06ba \u067e\u0627\u0646\u06cc \u0688\u0627\u0644\u06cc\u06ba"\n    \u2193 Output: [\u0394x, \u0394y, \u0394z, gripper_force]\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"RT-1 \u067e\u0631 Performance \u0628\u06c1\u062a\u0631\u06cc\u0627\u06ba:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Emergent skills"}),': robot data \u0645\u06cc\u06ba \u06a9\u0628\u06be\u06cc \u0646\u06c1 \u062f\u06cc\u06a9\u06be\u06d2 \u06af\u0626\u06d2 \u06a9\u0627\u0645 \u0627\u0646\u062c\u0627\u0645 \u062f\u06d2 \u0633\u06a9\u062a\u0627 \u06c1\u06d2 (\u0645\u062b\u0644\u0627\u064b\u060c "\u06a9\u06cc\u0644\u06d2 \u06a9\u0648 Taylor Swift \u06a9\u06d2 \u067e\u0627\u0633 \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u06cc\u06ba" \u2192 \u06a9\u06cc\u0644\u06d2 \u06a9\u0648 Taylor Swift \u06a9\u06d2 poster \u06a9\u06cc \u0637\u0631\u0641 \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2)']}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Symbol understanding"}),': \u0628\u0631\u0627\u0646\u0688 \u06a9\u06d2 \u0646\u0627\u0645\u0648\u06ba \u0633\u06d2 \u0627\u0634\u06cc\u0627\u0621 \u06a9\u0648 \u067e\u06c1\u0686\u0627\u0646\u062a\u0627 \u06c1\u06d2 (\u0645\u062b\u0644\u0627\u064b\u060c "Coke \u06a9\u0627 \u06a9\u06cc\u0646 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba")']}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Zero-shot generalization"}),": \u0628\u0627\u0644\u06a9\u0644 \u0646\u0626\u06d2 \u06a9\u0627\u0645\u0648\u06ba \u067e\u0631 62% \u06a9\u0627\u0645\u06cc\u0627\u0628\u06cc"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u062b\u0627\u0644:"})}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u06c1\u062f\u0627\u06cc\u062a:"}),' "\u0633\u06cc\u0628 \u06a9\u0648 \u06a9\u062a\u06d2 \u06a9\u06cc \u062a\u0635\u0648\u06cc\u0631 \u06a9\u06cc \u0637\u0631\u0641 \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u06cc\u06ba"']}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u06a9\u06cc\u0627 \u06c1\u0648\u062a\u0627 \u06c1\u06d2:"})}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:'RT-2 "\u0633\u06cc\u0628" \u0627\u0648\u0631 "\u06a9\u062a\u06d2 \u06a9\u06cc \u062a\u0635\u0648\u06cc\u0631" \u06a9\u0648 \u067e\u06c1\u0686\u0627\u0646\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 CLIP \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2'}),"\n",(0,r.jsx)(e.li,{children:"\u0633\u06cc\u0628 \u06a9\u0648 \u06a9\u062a\u06d2 \u06a9\u06cc \u0637\u0631\u0641 \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u062d\u0631\u06a9\u062a \u06a9\u06cc \u0645\u0646\u0635\u0648\u0628\u06c1 \u0628\u0646\u062f\u06cc \u06a9\u0631\u062a\u0627 \u06c1\u06d2"}),"\n",(0,r.jsx)(e.li,{children:"Closed-loop control \u06a9\u06d2 \u0633\u0627\u062a\u06be \u0639\u0645\u0644 \u06a9\u0648 execute \u06a9\u0631\u062a\u0627 \u06c1\u06d2"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"\u06a9\u0648\u0626\u06cc \u0648\u0627\u0636\u062d object detection \u06cc\u0627 motion planning code \u0646\u06c1\u06cc\u06ba\u2014\u06cc\u06c1 \u0633\u0628 \u0633\u06cc\u06a9\u06be\u0627 \u06c1\u0648\u0627 \u06c1\u06d2!"}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"vla-models-\u06a9\u06cc\u0633\u06d2-\u06a9\u0627\u0645-\u06a9\u0631\u062a\u06d2-\u06c1\u06cc\u06ba-\u0642\u062f\u0645-\u0628\u06c1-\u0642\u062f\u0645",children:"VLA Models \u06a9\u06cc\u0633\u06d2 \u06a9\u0627\u0645 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba: \u0642\u062f\u0645 \u0628\u06c1 \u0642\u062f\u0645"}),"\n",(0,r.jsx)(e.p,{children:"\u0622\u0626\u06cc\u06d2 \u062f\u06cc\u06a9\u06be\u06cc\u06ba \u06a9\u06c1 VLA model \u0627\u06cc\u06a9 command \u06a9\u0648 \u06a9\u06cc\u0633\u06d2 process \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u06d4"}),"\n",(0,r.jsx)(e.h3,{id:"\u0645\u062b\u0627\u0644-\u06a9\u0627-\u06a9\u0627\u0645-\u0633\u0631\u062e-\u0645\u06af-\u0627\u0679\u06be\u0627\u0626\u06cc\u06ba",children:'\u0645\u062b\u0627\u0644 \u06a9\u0627 \u06a9\u0627\u0645: "\u0633\u0631\u062e \u0645\u06af \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"'}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 1: Image Encoding"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Camera images (\u0645\u062e\u062a\u0644\u0641 \u0632\u0627\u0648\u06cc\u0648\u06ba \u0633\u06d2 6 views)\nimages = [camera1.read(), camera2.read(), ..., camera6.read()]\n\n# EfficientNet \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631 \u06a9\u06d2 images encode \u06a9\u0631\u06cc\u06ba (ImageNet \u067e\u0631 pretrained)\nimage_encoder = EfficientNet()\nvisual_features = image_encoder(images)  # Shape: [6, 512]\n\n# Cameras \u0645\u06cc\u06ba pool \u06a9\u0631\u06cc\u06ba\nvisual_tokens = pool(visual_features)  # Shape: [512]\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 2: Language Encoding"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# \u0635\u0627\u0631\u0641 \u06a9\u06cc \u06c1\u062f\u0627\u06cc\u062a\ninstruction = "\u0633\u0631\u062e \u0645\u06af \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"\n\n# Universal Sentence Encoder \u06a9\u06d2 \u0633\u0627\u062a\u06be encode \u06a9\u0631\u06cc\u06ba\nlanguage_encoder = UniversalSentenceEncoder()\nlanguage_tokens = language_encoder(instruction)  # Shape: [512]\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 3: Transformer Fusion"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Vision \u0627\u0648\u0631 language \u06a9\u0648 concatenate \u06a9\u0631\u06cc\u06ba\ninput_tokens = concat(visual_tokens, language_tokens)  # Shape: [1024]\n\n# Transformer \u06a9\u06d2 \u0630\u0631\u06cc\u0639\u06d2 pass \u06a9\u0631\u06cc\u06ba\ntransformer = TransformerDecoder(layers=8, heads=128)\naction_logits = transformer(input_tokens)  # Shape: [11]\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 4: Action Decoding"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Action space: [x, y, z, roll, pitch, yaw, gripper, terminate]\naction = decode_action(action_logits)\n\n# \u0645\u062b\u0627\u0644 \u06a9\u0627 output:\n# [\u0394x: +0.02m, \u0394y: -0.01m, \u0394z: +0.05m,  # \u0645\u06af \u06a9\u06cc \u0637\u0631\u0641 \u0645\u0646\u062a\u0642\u0644 \u06c1\u0648\u06ba\n#  roll: 0\xb0, pitch: 45\xb0, yaw: 0\xb0,       # Gripper \u06a9\u0648 \u062c\u06be\u06a9\u0627\u0626\u06cc\u06ba\n#  gripper: CLOSED, terminate: False]   # Gripper \u0628\u0646\u062f \u06a9\u0631\u06cc\u06ba\u060c \u062c\u0627\u0631\u06cc \u0631\u06a9\u06be\u06cc\u06ba\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 5: Robot Execution"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# ROS 2 \u06a9\u0648 action \u0628\u06be\u06cc\u062c\u06cc\u06ba\njoint_state_msg = compute_inverse_kinematics(action)\njoint_pub.publish(joint_state_msg)\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 6: \u062f\u06c1\u0631\u0627\u0626\u06cc\u06ba"})}),"\n",(0,r.jsx)(e.p,{children:"Model 3 Hz \u067e\u0631 \u0686\u0644\u062a\u0627 \u06c1\u06d2\u060c \u06a9\u0627\u0645 \u0645\u06a9\u0645\u0644 \u06c1\u0648\u0646\u06d2 \u062a\u06a9 \u0646\u0626\u06d2 camera frames \u06a9\u06cc \u0628\u0646\u06cc\u0627\u062f \u067e\u0631 \u0645\u0633\u0644\u0633\u0644 adjust \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u06d4"}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"vla-models-\u06a9\u06cc-\u062a\u0631\u0628\u06cc\u062a-imitation-learning",children:"VLA Models \u06a9\u06cc \u062a\u0631\u0628\u06cc\u062a: Imitation Learning"}),"\n",(0,r.jsxs)(e.p,{children:["VLA models ",(0,r.jsx)(e.strong,{children:"imitation learning"})," \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631 \u06a9\u06d2 \u062a\u0631\u0628\u06cc\u062a \u06cc\u0627\u0641\u062a\u06c1 \u06c1\u06cc\u06ba: \u0645\u0627\u06c1\u0631 demonstrations \u0633\u06d2 \u0633\u06cc\u06a9\u06be\u0646\u0627\u06d4"]}),"\n",(0,r.jsx)(e.h3,{id:"\u062a\u0631\u0628\u06cc\u062a\u06cc-\u0639\u0645\u0644",children:"\u062a\u0631\u0628\u06cc\u062a\u06cc \u0639\u0645\u0644"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 1: Demonstrations \u062c\u0645\u0639 \u06a9\u0631\u06cc\u06ba"})}),"\n",(0,r.jsx)(e.p,{children:"\u0627\u0646\u0633\u0627\u0646 robot \u06a9\u0648 teleoperate \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba \u06a9\u06c1 \u06a9\u0627\u0645 \u0645\u06a9\u0645\u0644 \u06a9\u0631\u06cc\u06ba \u062c\u0628\u06a9\u06c1 record \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u06c1\u0631 timestep \u067e\u0631 camera images"}),"\n",(0,r.jsx)(e.li,{children:'Language instructions (\u0645\u062b\u0644\u0627\u064b\u060c "\u0633\u0631\u062e \u0628\u0644\u0627\u06a9 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba")'}),"\n",(0,r.jsx)(e.li,{children:"Robot actions (joint positions\u060c gripper state)"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 2: Dataset \u0628\u0646\u0627\u0626\u06cc\u06ba"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# \u0645\u062b\u0627\u0644 \u06a9\u0627 dataset entry\n{\n    "instruction": "\u0633\u0631\u062e \u0628\u0644\u0627\u06a9 \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba",\n    "images": [img_t0, img_t1, ..., img_t100],  # 100 frames @ 3 Hz = 33 \u0633\u06cc\u06a9\u0646\u0688\n    "actions": [a_t0, a_t1, ..., a_t100],       # \u0645\u062a\u0639\u0644\u0642\u06c1 actions\n}\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 3: Behavioral Cloning \u06a9\u06d2 \u0633\u0627\u062a\u06be \u062a\u0631\u0628\u06cc\u062a \u062f\u06cc\u06ba"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# Loss function: \u0645\u0627\u06c1\u0631 actions \u06a9\u06cc \u067e\u06cc\u0634 \u06af\u0648\u0626\u06cc \u06a9\u0631\u06cc\u06ba\nloss = MSE(predicted_actions, expert_actions)\n\n# \u062a\u0631\u0628\u06cc\u062a\u06cc loop\nfor batch in dataset:\n    images, instructions, expert_actions = batch\n    predicted_actions = vla_model(images, instructions)\n    loss = criterion(predicted_actions, expert_actions)\n    loss.backward()\n    optimizer.step()\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 4: Robot \u067e\u0631 Fine-Tune \u06a9\u0631\u06cc\u06ba"})}),"\n",(0,r.jsxs)(e.p,{children:["Model \u06a9\u0648 robot \u067e\u0631 \u062a\u0639\u06cc\u0646\u0627\u062a \u06a9\u0631\u06cc\u06ba \u0627\u0648\u0631 ",(0,r.jsx)(e.strong,{children:"on-policy"})," data \u062c\u0645\u0639 \u06a9\u0631\u06cc\u06ba (\u0633\u06cc\u06a9\u06be\u06cc \u06c1\u0648\u0626\u06cc policy \u0633\u06d2 data\u060c \u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u0633\u06d2 \u0646\u06c1\u06cc\u06ba)\u06d4 \u06cc\u06c1 distribution shift \u06a9\u0648 \u062f\u0631\u0633\u062a \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u06d4"]}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# DAgger (Dataset Aggregation) algorithm\n1. \u0645\u0648\u062c\u0648\u062f\u06c1 policy \u03c0 \u062a\u0639\u06cc\u0646\u0627\u062a \u06a9\u0631\u06cc\u06ba\n2. \u062c\u0628 policy \u0646\u0627\u06a9\u0627\u0645 \u06c1\u0648\u060c \u0627\u0646\u0633\u0627\u0646 action \u06a9\u0648 \u062f\u0631\u0633\u062a \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n3. (state, corrected_action) \u06a9\u0648 dataset \u0645\u06cc\u06ba \u0634\u0627\u0645\u0644 \u06a9\u0631\u06cc\u06ba\n4. Policy \u06a9\u0648 \u062f\u0648\u0628\u0627\u0631\u06c1 \u062a\u0631\u0628\u06cc\u062a \u062f\u06cc\u06ba\n5. \u062f\u06c1\u0631\u0627\u0626\u06cc\u06ba\n"})}),"\n",(0,r.jsx)(e.h3,{id:"vla-\u062a\u0631\u0628\u06cc\u062a-\u06a9\u06d2-\u0644\u06cc\u06d2-datasets",children:"VLA \u062a\u0631\u0628\u06cc\u062a \u06a9\u06d2 \u0644\u06cc\u06d2 Datasets"}),"\n",(0,r.jsxs)(e.table,{children:[(0,r.jsx)(e.thead,{children:(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.th,{children:"Dataset"}),(0,r.jsx)(e.th,{children:"\u0633\u0627\u0626\u0632"}),(0,r.jsx)(e.th,{children:"\u06a9\u0627\u0645"}),(0,r.jsx)(e.th,{children:"\u0630\u0631\u06cc\u0639\u06c1"})]})}),(0,r.jsxs)(e.tbody,{children:[(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"RT-1 Dataset"})}),(0,r.jsx)(e.td,{children:"130K demos"}),(0,r.jsx)(e.td,{children:"Pick-and-place\u060c drawer opening"}),(0,r.jsx)(e.td,{children:"Google Robot Kitchens"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"Open-X Embodiment"})}),(0,r.jsx)(e.td,{children:"1M+ demos"}),(0,r.jsx)(e.td,{children:"160+ \u06a9\u0627\u0645\u060c 22 robot types"}),(0,r.jsx)(e.td,{children:"Multi-institution collaboration"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"CALVIN"})}),(0,r.jsx)(e.td,{children:"24K demos"}),(0,r.jsx)(e.td,{children:"Long-horizon \u06a9\u0627\u0645 (\u0627\u0648\u0633\u0637 34 steps)"}),(0,r.jsx)(e.td,{children:"Simulation (table-top)"})]}),(0,r.jsxs)(e.tr,{children:[(0,r.jsx)(e.td,{children:(0,r.jsx)(e.strong,{children:"RoboTurk"})}),(0,r.jsx)(e.td,{children:"100K demos"}),(0,r.jsx)(e.td,{children:"Manipulation \u06a9\u0627\u0645"}),(0,r.jsx)(e.td,{children:"Simulated + Real"})]})]})]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Open-X Embodiment"})," (2023) \u0633\u0628 \u0633\u06d2 \u0628\u0691\u0627 \u06c1\u06d2: 22 \u0645\u062e\u062a\u0644\u0641 robot platforms \u0633\u06d2 data \u06a9\u0648 \u06cc\u06a9\u062c\u0627 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\u060c ",(0,r.jsx)(e.strong,{children:"cross-embodiment learning"})," \u06a9\u0648 \u0645\u0645\u06a9\u0646 \u0628\u0646\u0627\u062a\u0627 \u06c1\u06d2 (\u0627\u06cc\u06a9 robot \u067e\u0631 \u062a\u0631\u0628\u06cc\u062a \u062f\u06cc\u06ba\u060c \u062f\u0648\u0633\u0631\u06d2 \u0645\u06cc\u06ba \u0645\u0646\u062a\u0642\u0644 \u06a9\u0631\u06cc\u06ba)\u06d4"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"vla-\u06a9\u0648-ros-2-\u0633\u06d2-\u062c\u0648\u0691\u0646\u0627",children:"VLA \u06a9\u0648 ROS 2 \u0633\u06d2 \u062c\u0648\u0691\u0646\u0627"}),"\n",(0,r.jsx)(e.p,{children:"VLA models \u0639\u0627\u0645 \u0637\u0648\u0631 \u067e\u0631 Python (PyTorch/TensorFlow) \u0645\u06cc\u06ba \u062a\u0631\u0628\u06cc\u062a \u06cc\u0627\u0641\u062a\u06c1 \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba\u06d4 \u06cc\u06c1\u0627\u06ba \u0627\u0646\u06c1\u06cc\u06ba ROS 2 system \u0645\u06cc\u06ba integrate \u06a9\u0631\u0646\u06d2 \u06a9\u0627 \u0637\u0631\u06cc\u0642\u06c1 \u06c1\u06d2\u06d4"}),"\n",(0,r.jsx)(e.h3,{id:"\u0645\u062b\u0627\u0644-robot-\u067e\u0631-rt-2-\u062a\u0639\u06cc\u0646\u0627\u062a-\u06a9\u0631\u0646\u0627",children:"\u0645\u062b\u0627\u0644: Robot \u067e\u0631 RT-2 \u062a\u0639\u06cc\u0646\u0627\u062a \u06a9\u0631\u0646\u0627"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0641\u0646 \u062a\u0639\u0645\u06cc\u0631:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"ROS 2 Node: VLA Control\n    \u2193 Subscribe: /camera/image, /speech/transcript\n    \u2193 Publish: /joint_commands\n    \u2193 \u0627\u0633\u062a\u0639\u0645\u0627\u0644: RT-2 PyTorch model\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Implementation:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image, JointState\nfrom std_msgs.msg import String\nimport torch\nfrom rt2_model import RT2  # \u0641\u0631\u0636\u06cc RT-2 implementation\n\nclass VLAControlNode(Node):\n    def __init__(self):\n        super().__init__('vla_control_node')\n\n        # RT-2 model \u0644\u0648\u0688 \u06a9\u0631\u06cc\u06ba\n        self.model = RT2.from_pretrained('google/rt-2-base')\n        self.model.eval()  # Inference mode\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.model.to(self.device)\n\n        # Camera \u0627\u0648\u0631 language input \u06a9\u0648 subscribe \u06a9\u0631\u06cc\u06ba\n        self.create_subscription(Image, '/camera/image', self.image_callback, 10)\n        self.create_subscription(String, '/speech/transcript', self.command_callback, 10)\n\n        # Robot actions \u06a9\u06d2 \u0644\u06cc\u06d2 publisher\n        self.action_pub = self.create_publisher(JointState, '/joint_commands', 10)\n\n        # State\n        self.current_image = None\n        self.current_instruction = None\n\n        # 3 Hz \u067e\u0631 control loop (RT-2 inference rate)\n        self.create_timer(1.0 / 3.0, self.control_loop)\n\n        self.get_logger().info('VLA Control Node ready')\n\n    def image_callback(self, msg):\n        # ROS Image \u06a9\u0648 numpy array \u0645\u06cc\u06ba convert \u06a9\u0631\u06cc\u06ba\n        self.current_image = self.ros_img_to_numpy(msg)\n\n    def command_callback(self, msg):\n        self.current_instruction = msg.data\n        self.get_logger().info(f'\u0646\u0626\u06cc \u06c1\u062f\u0627\u06cc\u062a: {self.current_instruction}')\n\n    def control_loop(self):\n        if self.current_image is None or self.current_instruction is None:\n            return  # \u062f\u0648\u0646\u0648\u06ba inputs \u06a9\u0627 \u0627\u0646\u062a\u0638\u0627\u0631 \u06a9\u0631\u06cc\u06ba\n\n        # Inputs \u062a\u06cc\u0627\u0631 \u06a9\u0631\u06cc\u06ba\n        image_tensor = self.preprocess_image(self.current_image)\n        instruction_tensor = self.tokenize_instruction(self.current_instruction)\n\n        # VLA model \u0686\u0644\u0627\u0626\u06cc\u06ba\n        with torch.no_grad():\n            action = self.model(image_tensor, instruction_tensor)\n\n        # Action \u06a9\u0648 JointState message \u0645\u06cc\u06ba convert \u06a9\u0631\u06cc\u06ba\n        joint_msg = self.action_to_joint_state(action)\n        self.action_pub.publish(joint_msg)\n\n        self.get_logger().info(f'Action \u0634\u0627\u0626\u0639 \u06a9\u06cc\u0627: {action.tolist()}')\n\n    def preprocess_image(self, img):\n        # 224x224 \u0645\u06cc\u06ba resize \u06a9\u0631\u06cc\u06ba\u060c normalize \u06a9\u0631\u06cc\u06ba\u060c tensor \u0645\u06cc\u06ba convert \u06a9\u0631\u06cc\u06ba\n        img_resized = cv2.resize(img, (224, 224))\n        img_tensor = torch.from_numpy(img_resized).permute(2, 0, 1).float() / 255.0\n        img_tensor = img_tensor.unsqueeze(0).to(self.device)\n        return img_tensor\n\n    def tokenize_instruction(self, text):\n        # Model \u06a9\u06d2 tokenizer \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u06cc\u06ba (\u0645\u062b\u0644\u0627\u064b\u060c SentencePiece)\n        tokens = self.model.tokenizer(text, return_tensors='pt').to(self.device)\n        return tokens\n\n    def action_to_joint_state(self, action):\n        # VLA action [\u0394x, \u0394y, \u0394z, ...] \u06a9\u0648 joint positions \u0645\u06cc\u06ba convert \u06a9\u0631\u06cc\u06ba\n        # \u0627\u0633 \u06a9\u06d2 \u0644\u06cc\u06d2 inverse kinematics (IK) \u06a9\u06cc \u0636\u0631\u0648\u0631\u062a \u06c1\u06d2\n        joint_positions = self.compute_ik(action)\n\n        joint_msg = JointState()\n        joint_msg.name = ['joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6', 'gripper']\n        joint_msg.position = joint_positions.tolist()\n\n        return joint_msg\n\n    def compute_ik(self, action):\n        # Placeholder: IK \u06a9\u06d2 \u0644\u06cc\u06d2 PyBullet \u06cc\u0627 MoveIt \u062c\u06cc\u0633\u06cc library \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u06cc\u06ba\n        # action format: [\u0394x, \u0394y, \u0394z, roll, pitch, yaw, gripper_state]\n        # Output: joint angles\n        return torch.rand(7)  # Dummy values\n\n    def ros_img_to_numpy(self, msg):\n        # ROS Image \u06a9\u0648 OpenCV format \u0645\u06cc\u06ba convert \u06a9\u0631\u06cc\u06ba\n        import cv_bridge\n        bridge = cv_bridge.CvBridge()\n        return bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')\n\ndef main(args=None):\n    rclpy.init(args=args)\n    node = VLAControlNode()\n    rclpy.spin(node)\n    node.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u06cc\u06c1 Node \u06a9\u06cc\u0627 \u06a9\u0631\u062a\u0627 \u06c1\u06d2:"})}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Camera images \u0627\u0648\u0631 voice commands \u06a9\u0648 subscribe \u06a9\u0631\u062a\u0627 \u06c1\u06d2"}),"\n",(0,r.jsx)(e.li,{children:"Actions \u06a9\u06cc \u067e\u06cc\u0634 \u06af\u0648\u0626\u06cc \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 3 Hz \u067e\u0631 RT-2 model \u0686\u0644\u0627\u062a\u0627 \u06c1\u06d2"}),"\n",(0,r.jsx)(e.li,{children:"Inverse kinematics \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631 \u06a9\u06d2 actions \u06a9\u0648 joint commands \u0645\u06cc\u06ba convert \u06a9\u0631\u062a\u0627 \u06c1\u06d2"}),"\n",(0,r.jsxs)(e.li,{children:["Robot execution \u06a9\u06d2 \u0644\u06cc\u06d2 ",(0,r.jsx)(e.code,{children:"/joint_commands"})," \u0645\u06cc\u06ba \u0634\u0627\u0626\u0639 \u06a9\u0631\u062a\u0627 \u06c1\u06d2"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"\u0622\u0648\u0627\u0632--\u0628\u0635\u0627\u0631\u062a--\u0639\u0645\u0644-\u0645\u06a9\u0645\u0644-\u0645\u062b\u0627\u0644",children:"\u0622\u0648\u0627\u0632 \u2192 \u0628\u0635\u0627\u0631\u062a \u2192 \u0639\u0645\u0644: \u0645\u06a9\u0645\u0644 \u0645\u062b\u0627\u0644"}),"\n",(0,r.jsx)(e.p,{children:"\u0622\u0626\u06cc\u06d2 \u0627\u06cc\u06a9 \u0645\u06a9\u0645\u0644 pipeline \u0628\u0646\u0627\u0626\u06cc\u06ba \u062c\u06c1\u0627\u06ba \u0635\u0627\u0631\u0641 robot \u06a9\u0648 \u0628\u0648\u0644\u06cc \u06c1\u0648\u0626\u06cc commands \u062f\u06d2 \u0633\u06a9\u062a\u0627 \u06c1\u06d2\u06d4"}),"\n",(0,r.jsx)(e.h3,{id:"system-architecture",children:"System Architecture"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:"\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Microphone \u2502 \u2192 /audio/raw\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Whisper Node \u2502 \u2192 /speech/transcript\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     /camera/image\n\u2502  VLA Node (RT-2) \u2502 \u2190 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2193\n   /joint_commands\n         \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Robot Hardware \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\u0645\u0631\u062d\u0644\u06c1-1-whisper-\u06a9\u06d2-\u0633\u0627\u062a\u06be-speech-to-text",children:"\u0645\u0631\u062d\u0644\u06c1 1: Whisper \u06a9\u06d2 \u0633\u0627\u062a\u06be Speech-to-Text"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import rclpy\nfrom rclpy.node import Node\nfrom audio_msgs.msg import AudioData\nfrom std_msgs.msg import String\nimport whisper\n\nclass WhisperNode(Node):\n    def __init__(self):\n        super().__init__('whisper_node')\n\n        # Whisper model \u0644\u0648\u0688 \u06a9\u0631\u06cc\u06ba\n        self.model = whisper.load_model('base')  # 'tiny', 'base', 'small', 'medium', 'large'\n\n        # Audio \u06a9\u0648 subscribe \u06a9\u0631\u06cc\u06ba\n        self.create_subscription(AudioData, '/audio/raw', self.audio_callback, 10)\n\n        # Transcripts \u06a9\u06d2 \u0644\u06cc\u06d2 publisher\n        self.transcript_pub = self.create_publisher(String, '/speech/transcript', 10)\n\n        self.get_logger().info('Whisper Node \u062a\u06cc\u0627\u0631 \u06c1\u06d2')\n\n    def audio_callback(self, msg):\n        # Audio \u06a9\u0648 numpy array \u0645\u06cc\u06ba convert \u06a9\u0631\u06cc\u06ba\n        audio_array = np.frombuffer(msg.data, dtype=np.float32)\n\n        # Whisper \u06a9\u06d2 \u0633\u0627\u062a\u06be transcribe \u06a9\u0631\u06cc\u06ba\n        result = self.model.transcribe(audio_array)\n        transcript = result['text']\n\n        self.get_logger().info(f'Transcript: {transcript}')\n\n        # Transcript \u0634\u0627\u0626\u0639 \u06a9\u0631\u06cc\u06ba\n        transcript_msg = String()\n        transcript_msg.data = transcript\n        self.transcript_pub.publish(transcript_msg)\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\u0645\u0631\u062d\u0644\u06c1-2-\u0645\u06a9\u0645\u0644-system-\u0644\u0627\u0646\u0686-\u06a9\u0631\u06cc\u06ba",children:"\u0645\u0631\u062d\u0644\u06c1 2: \u0645\u06a9\u0645\u0644 System \u0644\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:"# Terminal 1: Camera node \u0644\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba\nros2 run usb_cam usb_cam_node\n\n# Terminal 2: Whisper node \u0644\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba\nros2 run vla_control whisper_node\n\n# Terminal 3: VLA control node \u0644\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba\nros2 run vla_control vla_control_node\n\n# Terminal 4: Robot hardware interface \u0644\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba\nros2 launch my_robot robot.launch.py\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\u0645\u0631\u062d\u0644\u06c1-3-\u0627\u0633-\u06a9\u06cc-\u062c\u0627\u0646\u0686-\u06a9\u0631\u06cc\u06ba",children:"\u0645\u0631\u062d\u0644\u06c1 3: \u0627\u0633 \u06a9\u06cc \u062c\u0627\u0646\u0686 \u06a9\u0631\u06cc\u06ba"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-bash",children:'# \u0635\u0627\u0631\u0641 \u0628\u0648\u0644\u062a\u0627 \u06c1\u06d2: "\u0633\u0631\u062e \u06a9\u067e \u0627\u0679\u06be\u0627\u0626\u06cc\u06ba"\n# \u2192 Whisper "/speech/transcript" \u0645\u06cc\u06ba transcribe \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# \u2192 VLA node image + transcript \u0648\u0635\u0648\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# \u2192 RT-2 action \u06a9\u06cc \u067e\u06cc\u0634 \u06af\u0648\u0626\u06cc \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# \u2192 Robot \u062d\u0631\u06a9\u062a execute \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"capstone-\u062e\u0648\u062f\u06a9\u0627\u0631-humanoid-assistant-\u0628\u0646\u0627\u0646\u0627",children:"Capstone: \u062e\u0648\u062f\u06a9\u0627\u0631 Humanoid Assistant \u0628\u0646\u0627\u0646\u0627"}),"\n",(0,r.jsx)(e.p,{children:"\u0622\u0626\u06cc\u06d2 \u0627\u06cc\u06a9 \u0645\u06a9\u0645\u0644 \u062e\u0648\u062f\u06a9\u0627\u0631 humanoid \u0688\u06cc\u0632\u0627\u0626\u0646 \u06a9\u0631\u06cc\u06ba \u062c\u0648 \u06af\u06be\u0631\u06cc\u0644\u0648 \u06a9\u0627\u0645 \u0627\u0646\u062c\u0627\u0645 \u062f\u06d2 \u0633\u06a9\u062a\u0627 \u06c1\u06d2\u06d4"}),"\n",(0,r.jsx)(e.h3,{id:"system-\u06a9\u06cc-\u0636\u0631\u0648\u0631\u06cc\u0627\u062a",children:"System \u06a9\u06cc \u0636\u0631\u0648\u0631\u06cc\u0627\u062a"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0635\u0644\u0627\u062d\u06cc\u062a\u06cc\u06ba:"})}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"\u0622\u0648\u0627\u0632 \u06a9\u06d2 \u062d\u06a9\u0645 \u06a9\u06cc \u062a\u0641\u06c1\u06cc\u0645"}),"\n",(0,r.jsx)(e.li,{children:"\u0627\u0634\u06cc\u0627\u0621 \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u0646\u0627 \u0627\u0648\u0631 tracking"}),"\n",(0,r.jsx)(e.li,{children:"\u0627\u0646\u062f\u0631\u0648\u0646\u06cc \u0645\u0627\u062d\u0648\u0644 \u0645\u06cc\u06ba navigation"}),"\n",(0,r.jsx)(e.li,{children:"Manipulation (\u0627\u0679\u06be\u0627\u0646\u0627\u060c \u0631\u06a9\u06be\u0646\u0627\u060c \u062f\u0631\u0648\u0627\u0632\u06d2 \u06a9\u06be\u0648\u0644\u0646\u0627)"}),"\n",(0,r.jsx)(e.li,{children:"\u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u062a\u0639\u0627\u0645\u0644 (\u0627\u0634\u0627\u0631\u06d2\u060c \u0686\u06c1\u0631\u06d2 \u06a9\u06d2 \u062a\u0627\u062b\u0631\u0627\u062a)"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"Hardware:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Humanoid Platform"}),": Figure 02\u060c Tesla Optimus\u060c \u06cc\u0627 Boston Dynamics Atlas"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Sensors"}),": RGB-D cameras (2)\u060c LiDAR\u060c IMU\u060c microphones (4)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compute"}),": NVIDIA Jetson AGX Orin (64 GB RAM\u060c 275 TOPS)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Actuators"}),": 25 DOF (\u0628\u0627\u0632\u0648: 7 \u06c1\u0631 \u0627\u06cc\u06a9\u060c \u0679\u0627\u0646\u06af\u06cc\u06ba: 6 \u06c1\u0631 \u0627\u06cc\u06a9\u060c torso: 3\u060c \u0633\u0631: 2)"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"software-architecture",children:"Software Architecture"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{children:'\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            High-Level Planning (GPT-4)           \u2502\n\u2502  \u06a9\u0627\u0645: "\u0645\u06cc\u0631\u06d2 \u0644\u06cc\u06d2 \u0633\u06cc\u0646\u0688\u0648\u0686 \u0628\u0646\u0627\u0626\u06cc\u06ba"               \u2502\n\u2502  \u2192 \u0630\u06cc\u0644\u06cc \u06a9\u0627\u0645: [\u0628\u0627\u0648\u0631\u0686\u06cc \u062e\u0627\u0646\u06d2 \u0645\u06cc\u06ba navigate \u06a9\u0631\u06cc\u06ba\u060c \u2502\n\u2502               fridge \u06a9\u06be\u0648\u0644\u06cc\u06ba\u060c \u0631\u0648\u0679\u06cc \u067e\u06a9\u0691\u06cc\u06ba\u060c       \u2502\n\u2502               \u067e\u0646\u06cc\u0631 \u067e\u06a9\u0691\u06cc\u06ba\u060c ...]                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         VLA Model (RT-2 / Custom)                \u2502\n\u2502  \u0630\u06cc\u0644\u06cc \u06a9\u0627\u0645: "\u0631\u0648\u0679\u06cc \u067e\u06a9\u0691\u06cc\u06ba"                       \u2502\n\u2502  Input: Camera + "\u0631\u0648\u0679\u06cc \u067e\u06a9\u0691\u06cc\u06ba"                 \u2502\n\u2502  Output: End-effector trajectory                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          Isaac ROS (Perception)                  \u2502\n\u2502  - Object detection (\u0631\u0648\u0679\u06cc\u060c \u067e\u0646\u06cc\u0631\u060c \u0648\u063a\u06cc\u0631\u06c1)       \u2502\n\u2502  - Visual SLAM (localization)                   \u2502\n\u2502  - Depth estimation (obstacle avoidance)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          ROS 2 Control (MoveIt 2)                \u2502\n\u2502  - Path planning (collision-free)               \u2502\n\u2502  - Inverse kinematics                           \u2502\n\u2502  - Joint trajectory execution                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          Robot Hardware                          \u2502\n\u2502  - Actuators (motors)                           \u2502\n\u2502  - Sensors (encoders, force/torque)             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n'})}),"\n",(0,r.jsx)(e.h3,{id:"implementation-flow",children:"Implementation Flow"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 1: GPT-4 \u06a9\u06d2 \u0633\u0627\u062a\u06be High-Level Planning"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'import openai\n\ndef plan_task(task):\n    prompt = f"""\n    \u0622\u067e \u0627\u06cc\u06a9 robot task planner \u06c1\u06cc\u06ba\u06d4 \u0627\u0633 \u06a9\u0627\u0645 \u06a9\u0648 \u0630\u06cc\u0644\u06cc \u06a9\u0627\u0645\u0648\u06ba \u0645\u06cc\u06ba \u062a\u0642\u0633\u06cc\u0645 \u06a9\u0631\u06cc\u06ba:\n    \u06a9\u0627\u0645: {task}\n\n    Output format (JSON):\n    {{"subtasks": ["subtask1", "subtask2", ...]}}\n    """\n\n    response = openai.ChatCompletion.create(\n        model="gpt-4",\n        messages=[{"role": "user", "content": prompt}]\n    )\n\n    plan = json.loads(response.choices[0].message.content)\n    return plan[\'subtasks\']\n\n# \u0645\u062b\u0627\u0644\ntask = "\u0645\u06cc\u0631\u06d2 \u0644\u06cc\u06d2 \u0633\u06cc\u0646\u0688\u0648\u0686 \u0628\u0646\u0627\u0626\u06cc\u06ba"\nsubtasks = plan_task(task)\n# Output: ["\u0628\u0627\u0648\u0631\u0686\u06cc \u062e\u0627\u0646\u06d2 \u0645\u06cc\u06ba navigate \u06a9\u0631\u06cc\u06ba", "Fridge \u06a9\u06be\u0648\u0644\u06cc\u06ba", "\u0631\u0648\u0679\u06cc \u067e\u06a9\u0691\u06cc\u06ba", "\u067e\u0646\u06cc\u0631 \u067e\u06a9\u0691\u06cc\u06ba", "\u0633\u06cc\u0646\u0688\u0648\u0686 \u062c\u0648\u0691\u06cc\u06ba"]\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 2: VLA \u06a9\u06d2 \u0633\u0627\u062a\u06be \u06c1\u0631 \u0630\u06cc\u0644\u06cc \u06a9\u0627\u0645 Execute \u06a9\u0631\u06cc\u06ba"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"for subtask in subtasks:\n    # Subtask \u06a9\u0648 instruction \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 \u0634\u0627\u0626\u0639 \u06a9\u0631\u06cc\u06ba\n    instruction_msg = String()\n    instruction_msg.data = subtask\n    instruction_pub.publish(instruction_msg)\n\n    # VLA node \u0627\u0633\u06d2 \u0627\u0679\u06be\u0627\u062a\u0627 \u06c1\u06d2 \u0627\u0648\u0631 execute \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n    # \u062a\u06a9\u0645\u06cc\u0644 \u06a9\u06d2 signal \u06a9\u0627 \u0627\u0646\u062a\u0638\u0627\u0631 \u06a9\u0631\u06cc\u06ba\n    wait_for_completion()\n"})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 3: VLA Execution (RT-2)"})}),"\n",(0,r.jsx)(e.p,{children:"VLA node (\u067e\u06c1\u0644\u06d2 \u0633\u06d2) \u06c1\u0631 subtask \u0648\u0635\u0648\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2 \u0627\u0648\u0631 \u0627\u0633\u06d2 execute \u06a9\u0631\u062a\u0627 \u06c1\u06d2:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# VLA Node \u0648\u0635\u0648\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2: "\u0631\u0648\u0679\u06cc \u067e\u06a9\u0691\u06cc\u06ba"\n# \u2192 Camera \u06a9\u06d2 \u0630\u0631\u06cc\u0639\u06d2 environment \u062f\u06cc\u06a9\u06be\u062a\u0627 \u06c1\u06d2\n# \u2192 \u0631\u0648\u0679\u06cc \u06a9\u06cc \u0637\u0631\u0641 \u0645\u0646\u062a\u0642\u0644 \u06c1\u0648\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 action \u06a9\u06cc \u067e\u06cc\u0634 \u06af\u0648\u0626\u06cc \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# \u2192 Joint commands \u0634\u0627\u0626\u0639 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# \u2192 Robot \u0631\u0648\u0679\u06cc \u067e\u06a9\u0691\u062a\u0627 \u06c1\u06d2\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 4: Isaac ROS \u06a9\u06d2 \u0633\u0627\u062a\u06be Perception"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# Isaac ROS node scene \u0645\u06cc\u06ba "\u0631\u0648\u0679\u06cc" \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u062a\u0627 \u06c1\u06d2\n# Object location \u06a9\u0648 /detected_objects \u0645\u06cc\u06ba \u0634\u0627\u0626\u0639 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# VLA node actions \u06a9\u0648 \u0628\u06c1\u062a\u0631 \u0628\u0646\u0627\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0627\u0633\u06d2 \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n'})}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u0631\u062d\u0644\u06c1 5: MoveIt 2 \u06a9\u06d2 \u0633\u0627\u062a\u06be Motion Planning"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"# MoveIt 2 collision-free trajectory \u06a9\u06cc \u0645\u0646\u0635\u0648\u0628\u06c1 \u0628\u0646\u062f\u06cc \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# /joint_trajectory_controller \u0645\u06cc\u06ba \u0634\u0627\u0626\u0639 \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n# Robot \u062d\u0631\u06a9\u062a \u06a9\u0648 smoothly execute \u06a9\u0631\u062a\u0627 \u06c1\u06d2\n"})}),"\n",(0,r.jsx)(e.h3,{id:"\u062d\u0641\u0627\u0638\u062a-\u0627\u0648\u0631-\u0627\u0646\u0633\u0627\u0646\u06cc-\u062a\u0639\u0627\u0645\u0644",children:"\u062d\u0641\u0627\u0638\u062a \u0627\u0648\u0631 \u0627\u0646\u0633\u0627\u0646\u06cc \u062a\u0639\u0627\u0645\u0644"}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0627\u06c1\u0645 \u062d\u0641\u0627\u0638\u062a\u06cc \u062e\u0635\u0648\u0635\u06cc\u0627\u062a:"})}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Force/Torque Limits"}),": \u0627\u06af\u0631 \u0642\u0648\u062a 50N \u0633\u06d2 \u0632\u06cc\u0627\u062f\u06c1 \u06c1\u0648 \u062a\u0648 Motors \u067e\u0627\u0648\u0631 \u06a9\u0627\u0679 \u062f\u06cc\u062a\u06d2 \u06c1\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Emergency Stop"}),": Wireless e-stop button \u062a\u0645\u0627\u0645 \u062d\u0631\u06a9\u062a \u06a9\u0648 \u0631\u0648\u06a9 \u062f\u06cc\u062a\u0627 \u06c1\u06d2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Vision-Based Monitoring"}),": \u06a9\u0627\u0645 \u06a9\u06cc \u062c\u06af\u06c1 \u0645\u06cc\u06ba \u0627\u0646\u0633\u0627\u0646\u0648\u06ba \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u062a\u0627 \u06c1\u06d2 \u0627\u0648\u0631 \u0633\u0633\u062a \u06c1\u0648 \u062c\u0627\u062a\u0627 \u06c1\u06d2"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Compliance Control"}),": \u063a\u06cc\u0631 \u0645\u062a\u0648\u0642\u0639 \u0631\u0627\u0628\u0637\u06d2 \u067e\u0631 yield \u06c1\u0648\u0646\u06d2 \u0648\u0627\u0644\u06d2 \u0646\u0631\u0645 joints"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u062a\u0639\u0627\u0645\u0644:"})}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'# \u0627\u0646\u0633\u0627\u0646\u06cc \u0627\u0634\u0627\u0631\u0648\u06ba \u06a9\u0627 \u067e\u062a\u06c1 \u0644\u06af\u0627\u0626\u06cc\u06ba (\u0645\u062b\u0644\u0627\u064b\u060c "\u0631\u06a9\u06cc\u06ba" \u06c1\u0627\u062a\u06be \u06a9\u0627 \u0646\u0634\u0627\u0646)\ngesture = detect_gesture(camera_image)\n\nif gesture == "stop":\n    robot.stop_all_motion()\n    speak("\u0641\u0648\u0631\u06cc \u0637\u0648\u0631 \u067e\u0631 \u0631\u06a9 \u0631\u06c1\u0627 \u06c1\u0648\u06ba")\n\n# Feedback \u06a9\u06d2 \u0644\u06cc\u06d2 \u0686\u06c1\u0631\u06d2 \u06a9\u06d2 \u062a\u0627\u062b\u0631\u0627\u062a\nif task_success:\n    robot.display_emotion("\u062e\u0648\u0634")\nelse:\n    robot.display_emotion("confused")\n    speak("\u0645\u062c\u06be\u06d2 \u06cc\u0642\u06cc\u0646 \u0646\u06c1\u06cc\u06ba \u06a9\u06c1 \u06a9\u06cc\u0627 \u06a9\u0631\u0646\u0627 \u06c1\u06d2\u06d4 \u06a9\u06cc\u0627 \u0622\u067e \u0645\u062f\u062f \u06a9\u0631 \u0633\u06a9\u062a\u06d2 \u06c1\u06cc\u06ba\u061f")\n'})}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"\u0627\u06c1\u0645-\u0646\u06a9\u0627\u062a",children:"\u0627\u06c1\u0645 \u0646\u06a9\u0627\u062a"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"VLA models"})," vision\u060c language\u060c \u0627\u0648\u0631 action \u06a9\u0648 \u0627\u06cc\u06a9 \u0648\u0627\u062d\u062f end-to-end learnable system \u0645\u06cc\u06ba \u0645\u062a\u062d\u062f \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RT-1"})," \u0646\u06d2 130K \u062d\u0642\u06cc\u0642\u06cc \u062f\u0646\u06cc\u0627 \u06a9\u06d2 robot demos \u067e\u0631 imitation learning \u06a9\u0627 \u0645\u0638\u0627\u06c1\u0631\u06c1 \u06a9\u06cc\u0627"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"RT-2"})," emergent generalization \u06a9\u06d2 \u0644\u06cc\u06d2 internet-scale vision-language models \u0633\u06d2 \u0641\u0627\u0626\u062f\u06c1 \u0627\u0679\u06be\u0627\u062a\u0627 \u06c1\u06d2"]}),"\n",(0,r.jsxs)(e.li,{children:["VLA models control nodes \u06a9\u06d2 \u0637\u0648\u0631 \u067e\u0631 ",(0,r.jsx)(e.strong,{children:"ROS 2"})," \u06a9\u06d2 \u0633\u0627\u062a\u06be \u0628\u063a\u06cc\u0631 \u06a9\u0633\u06cc \u0631\u06a9\u0627\u0648\u0679 \u06a9\u06d2 integrate \u06c1\u0648\u062a\u06d2 \u06c1\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u0622\u0648\u0627\u0632 \u2192 \u0628\u0635\u0627\u0631\u062a \u2192 \u0639\u0645\u0644"})," pipelines \u0642\u062f\u0631\u062a\u06cc \u0627\u0646\u0633\u0627\u0646-\u0631\u0648\u0628\u0648\u0679 \u062a\u0639\u0627\u0645\u0644 \u06a9\u0648 \u0645\u0645\u06a9\u0646 \u0628\u0646\u0627\u062a\u06d2 \u06c1\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:["\u0627\u06cc\u06a9 \u0645\u06a9\u0645\u0644 \u062e\u0648\u062f\u06a9\u0627\u0631 humanoid ",(0,r.jsx)(e.strong,{children:"VLA"}),"\u060c ",(0,r.jsx)(e.strong,{children:"Isaac ROS"}),"\u060c ",(0,r.jsx)(e.strong,{children:"MoveIt 2"}),"\u060c \u0627\u0648\u0631 ",(0,r.jsx)(e.strong,{children:"GPT-4"})," \u06a9\u0648 \u06cc\u06a9\u062c\u0627 \u06a9\u0631\u062a\u0627 \u06c1\u06d2"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"\u06c1\u0627\u062a\u06be-\u0633\u06d2-\u0639\u0645\u0644\u06cc-\u0645\u0634\u0642",children:"\u06c1\u0627\u062a\u06be \u0633\u06d2 \u0639\u0645\u0644\u06cc \u0645\u0634\u0642"}),"\n",(0,r.jsx)(e.h3,{id:"\u0648\u0631\u0632\u0634-1-vla-inference-\u06a9\u06cc-\u0631\u0641\u062a\u0627\u0631-\u06a9\u0627-\u062d\u0633\u0627\u0628-\u0644\u06af\u0627\u0626\u06cc\u06ba",children:"\u0648\u0631\u0632\u0634 1: VLA Inference \u06a9\u06cc \u0631\u0641\u062a\u0627\u0631 \u06a9\u0627 \u062d\u0633\u0627\u0628 \u0644\u06af\u0627\u0626\u06cc\u06ba"}),"\n",(0,r.jsx)(e.p,{children:"\u0627\u06af\u0631 RT-2 3 Hz (333 ms \u0641\u06cc action) \u067e\u0631 \u0686\u0644\u062a\u0627 \u06c1\u06d2\u060c \u0627\u0648\u0631 \u0627\u06cc\u06a9 \u06a9\u0627\u0645 \u06a9\u0648 \u0645\u06a9\u0645\u0644 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 100 actions \u06a9\u06cc \u0636\u0631\u0648\u0631\u062a \u06c1\u06d2:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u06a9\u0627\u0645 \u06a9\u0648 \u06a9\u062a\u0646\u0627 \u0648\u0642\u062a \u0644\u06af\u062a\u0627 \u06c1\u06d2\u061f"}),"\n",(0,r.jsx)(e.li,{children:"\u0627\u06af\u0631 \u0622\u067e 2x \u062a\u06cc\u0632 GPU \u0645\u06cc\u06ba upgrade \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba\u060c \u062a\u0648 \u0646\u06cc\u0627 \u06a9\u0627\u0645 \u0645\u06a9\u0645\u0644 \u06c1\u0648\u0646\u06d2 \u06a9\u0627 \u0648\u0642\u062a \u06a9\u06cc\u0627 \u06c1\u06d2\u061f"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\u0648\u0631\u0632\u0634-2-vla-\u062a\u0631\u0628\u06cc\u062a\u06cc-dataset-\u0688\u06cc\u0632\u0627\u0626\u0646-\u06a9\u0631\u06cc\u06ba",children:"\u0648\u0631\u0632\u0634 2: VLA \u062a\u0631\u0628\u06cc\u062a\u06cc Dataset \u0688\u06cc\u0632\u0627\u0626\u0646 \u06a9\u0631\u06cc\u06ba"}),"\n",(0,r.jsx)(e.p,{children:"\u0622\u067e \u06a9\u067e\u0691\u06d2 \u062a\u06c1\u06c1 \u06a9\u0631\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 VLA model \u06a9\u06cc \u062a\u0631\u0628\u06cc\u062a \u062f\u06cc\u0646\u0627 \u0686\u0627\u06c1\u062a\u06d2 \u06c1\u06cc\u06ba\u06d4 \u0622\u067e \u06a9\u0648\u0646 \u0633\u06d2 demonstrations \u062c\u0645\u0639 \u06a9\u0631\u06cc\u06ba \u06af\u06d2\u061f"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u0627\u0634\u0627\u0631\u06c1:"})," \u062a\u0628\u062f\u06cc\u0644\u06cc\u0648\u06ba \u06a9\u06d2 \u0628\u0627\u0631\u06d2 \u0645\u06cc\u06ba \u0633\u0648\u0686\u06cc\u06ba (\u0642\u0645\u06cc\u0636 \u06a9\u06d2 \u0633\u0627\u0626\u0632\u060c fabric \u06a9\u06cc \u0627\u0642\u0633\u0627\u0645\u060c \u0627\u0628\u062a\u062f\u0627\u0626\u06cc positions)\u06d4"]}),"\n",(0,r.jsx)(e.h3,{id:"\u0648\u0631\u0632\u0634-3-hybrid-planning",children:"\u0648\u0631\u0632\u0634 3: Hybrid Planning"}),"\n",(0,r.jsx)(e.p,{children:'"\u0645\u06cc\u0631\u06d2 \u0644\u06cc\u06d2 \u0633\u06cc\u0646\u0688\u0648\u0686 \u0628\u0646\u0627\u0626\u06cc\u06ba" \u06a9\u0627\u0645 \u06a9\u06d2 \u0644\u06cc\u06d2\u060c \u06a9\u0648\u0646 \u0633\u06d2 \u0630\u06cc\u0644\u06cc \u06a9\u0627\u0645\u0648\u06ba \u06a9\u0648 \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u0646\u0627 \u0686\u0627\u06c1\u06cc\u06d2:'}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"GPT-4 planning"})," (high-level)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"VLA execution"})," (low-level)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Classical control"})," (precise motions)"]}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u0645\u062b\u0627\u0644 \u06a9\u0627 \u062c\u0648\u0627\u0628:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:'GPT-4: "\u0628\u0627\u0648\u0631\u0686\u06cc \u062e\u0627\u0646\u06d2 \u0645\u06cc\u06ba navigate \u06a9\u0631\u06cc\u06ba" (high-level)'}),"\n",(0,r.jsx)(e.li,{children:'VLA: "\u0631\u0648\u0679\u06cc \u067e\u06a9\u0691\u06cc\u06ba" (manipulation)'}),"\n",(0,r.jsx)(e.li,{children:'Classical: "45\xb0 \u0632\u0627\u0648\u06cc\u06d2 \u067e\u0631 \u0645\u06a9\u06be\u0646 \u067e\u06be\u06cc\u0644\u0627\u0626\u06cc\u06ba" (precise force control)'}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"\u0648\u0631\u0632\u0634-4-\u062d\u0641\u0627\u0638\u062a\u06cc-\u0646\u0627\u06a9\u0627\u0645\u06cc-\u06a9\u06d2-\u0637\u0631\u06cc\u0642\u06d2",children:"\u0648\u0631\u0632\u0634 4: \u062d\u0641\u0627\u0638\u062a\u06cc \u0646\u0627\u06a9\u0627\u0645\u06cc \u06a9\u06d2 \u0637\u0631\u06cc\u0642\u06d2"}),"\n",(0,r.jsx)(e.p,{children:"\u0627\u06cc\u06a9 humanoid \u0631\u06cc\u0633\u062a\u0648\u0631\u0627\u0646 \u0645\u06cc\u06ba \u0645\u0634\u0631\u0648\u0628\u0627\u062a \u067e\u06cc\u0634 \u06a9\u0631 \u0631\u06c1\u0627 \u06c1\u06d2\u06d4 3 \u0646\u0627\u06a9\u0627\u0645\u06cc \u06a9\u06d2 \u0637\u0631\u06cc\u0642\u06d2 \u0627\u0648\u0631 \u062a\u062e\u0641\u06cc\u0641 \u06a9\u06cc \u062d\u06a9\u0645\u062a \u0639\u0645\u0644\u06cc\u0627\u06ba \u0628\u062a\u0627\u0626\u06cc\u06ba\u06d4"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"\u0627\u0634\u0627\u0631\u06c1:"})," \u0628\u06c1\u0627\u0624\u060c \u062a\u0635\u0627\u062f\u0645\u060c \u0627\u0648\u0631 \u063a\u0644\u0637 \u0641\u06c1\u0645\u06cc\u0648\u06ba \u067e\u0631 \u063a\u0648\u0631 \u06a9\u0631\u06cc\u06ba\u06d4"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"\u0639\u0627\u0645-\u063a\u0644\u0637\u06cc\u0627\u06ba-\u062c\u0648-\u0627\u0628\u062a\u062f\u0627\u0626\u06cc-\u06a9\u0631\u062a\u06d2-\u06c1\u06cc\u06ba",children:"\u0639\u0627\u0645 \u063a\u0644\u0637\u06cc\u0627\u06ba \u062c\u0648 \u0627\u0628\u062a\u062f\u0627\u0626\u06cc \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u0635\u0631\u0641 \u06a9\u0627\u0645\u06cc\u0627\u0628 demos \u067e\u0631 \u062a\u0631\u0628\u06cc\u062a \u062f\u06cc\u0646\u0627"}),": \u063a\u0644\u0637\u06cc \u06a9\u06cc \u0628\u0627\u0632\u06cc\u0627\u0628\u06cc \u0633\u06a9\u06be\u0627\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0646\u0627\u06a9\u0627\u0645\u06cc \u06a9\u06d2 \u0645\u0639\u0627\u0645\u0644\u0627\u062a \u0634\u0627\u0645\u0644 \u06a9\u0631\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action frequency \u06a9\u0648 \u0646\u0638\u0631 \u0627\u0646\u062f\u0627\u0632 \u06a9\u0631\u0646\u0627"}),": VLA models \u0645\u0633\u062a\u0642\u0644 control rates (\u0645\u062b\u0644\u0627\u064b\u060c 3 Hz) \u06a9\u06cc \u062a\u0648\u0642\u0639 \u06a9\u0631\u062a\u06d2 \u06c1\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Demo environments \u0645\u06cc\u06ba Overfitting"}),": domain randomization \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631\u06cc\u06ba (lighting\u060c backgrounds)"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u0627\u0646\u0633\u0627\u0646\u06cc feedback \u0686\u06be\u0648\u0691\u0646\u0627"}),": \u0627\u0635\u0644\u0627\u062d\u06cc demonstrations (DAgger) \u06a9\u06d2 \u0633\u0627\u062a\u06be fine-tune \u06a9\u0631\u06cc\u06ba"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"\u062c\u0644\u062f \u062d\u0642\u06cc\u0642\u06cc hardware \u067e\u0631 testing \u0646\u06c1\u06cc\u06ba \u06a9\u0631\u0646\u0627"}),": VLAs \u06a9\u06d2 \u0644\u06cc\u06d2 \u0628\u06be\u06cc simulation-to-real gap \u0645\u0648\u062c\u0648\u062f \u06c1\u06d2"]}),"\n"]}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.h2,{id:"\u0622\u06af\u06d2-\u06a9\u06cc\u0627-\u06c1\u06d2",children:"\u0622\u06af\u06d2 \u06a9\u06cc\u0627 \u06c1\u06d2\u061f"}),"\n",(0,r.jsx)(e.p,{children:"\u0627\u06af\u0644\u06d2 \u0628\u0627\u0628 \u0645\u06cc\u06ba\u060c \u06c1\u0645:"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:"\u0634\u0631\u0648\u0639 \u0633\u06d2 custom VLA model \u06a9\u06cc \u062a\u0631\u0628\u06cc\u062a \u062f\u06cc\u06ba \u06af\u06d2"}),"\n",(0,r.jsx)(e.li,{children:"Teleoperation \u0627\u0633\u062a\u0639\u0645\u0627\u0644 \u06a9\u0631 \u06a9\u06d2 demonstrations \u062c\u0645\u0639 \u06a9\u0631\u06cc\u06ba \u06af\u06d2"}),"\n",(0,r.jsx)(e.li,{children:"\u0646\u0626\u06d2 \u06a9\u0627\u0645 \u067e\u0631 RT-2 \u06a9\u0648 fine-tune \u06a9\u0631\u06cc\u06ba \u06af\u06d2"}),"\n",(0,r.jsx)(e.li,{children:"ROS 2 \u06a9\u06d2 \u0633\u0627\u062a\u06be \u062d\u0642\u06cc\u0642\u06cc robot \u067e\u0631 model \u062a\u0639\u06cc\u0646\u0627\u062a \u06a9\u0631\u06cc\u06ba \u06af\u06d2"}),"\n"]}),"\n",(0,r.jsx)(e.p,{children:"\u0627\u0628 \u0622\u067e \u0646\u06d2 VLA paradigm \u0645\u06cc\u06ba \u0645\u06c1\u0627\u0631\u062a \u062d\u0627\u0635\u0644 \u06a9\u0631 \u0644\u06cc \u06c1\u06d2\u06d4 \u0627\u06af\u0644\u0627\u060c \u06c1\u0645 production-ready system \u0628\u0646\u0627\u0626\u06cc\u06ba \u06af\u06d2!"}),"\n",(0,r.jsx)(e.hr,{}),"\n",(0,r.jsx)(e.p,{children:(0,r.jsx)(e.strong,{children:"\u06af\u06c1\u0631\u06cc \u0633\u06cc\u06a9\u06be\u0646\u06d2 \u06a9\u06d2 \u0644\u06cc\u06d2 \u0648\u0633\u0627\u0626\u0644:"})}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://robotics-transformer.github.io/",children:"RT-1 Paper"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://deepmind.google/discover/blog/rt-2-new-model-translates-vision-and-language-into-action/",children:"RT-2 Paper"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://robotics-transformer-x.github.io/",children:"Open-X Embodiment Dataset"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://github.com/openai/whisper",children:"Whisper (OpenAI Speech Recognition)"})}),"\n",(0,r.jsx)(e.li,{children:(0,r.jsx)(e.a,{href:"https://control.ros.org/master/index.html",children:"ROS 2 Control Tutorials"})}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(h,{...n})}):h(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>l});var s=i(6540);const r={},t=s.createContext(r);function o(n){const e=s.useContext(t);return s.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(r):n.components||r:o(n.components),s.createElement(t.Provider,{value:e},n.children)}}}]);