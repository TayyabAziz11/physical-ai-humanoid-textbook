"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[535],{2781:(e,n,i)=>{i.d(n,{A:()=>t});var s=i(6540);const r={container:"container_rfuW",buttonGroup:"buttonGroup_PlP3",actionButton:"actionButton_Uyam",banner:"banner_o2gZ",bannerIcon:"bannerIcon_OknK",bannerText:"bannerText_QUdu",closeBanner:"closeBanner_dCt7"};var a=i(4848);function t({className:e}){const[n,i]=(0,s.useState)(!1),[t,o]=(0,s.useState)(!1);return(0,a.jsxs)("div",{className:`${r.container} ${e||""}`,children:[(0,a.jsxs)("div",{className:r.buttonGroup,children:[(0,a.jsx)("button",{className:r.actionButton,onClick:()=>{i(!0),o(!1)},"aria-label":"Personalize chapter content",children:"\u2728 Personalize for Me"}),(0,a.jsx)("button",{className:r.actionButton,onClick:()=>{o(!0),i(!1)},"aria-label":"View chapter in Urdu",children:"\ud83c\udf10 View in Urdu"})]}),n&&(0,a.jsxs)("div",{className:r.banner,role:"alert",children:[(0,a.jsx)("span",{className:r.bannerIcon,children:"\u2139\ufe0f"}),(0,a.jsx)("span",{className:r.bannerText,children:"Personalization coming soon \u2013 AI will adapt this chapter to your learning style and background"}),(0,a.jsx)("button",{className:r.closeBanner,onClick:()=>i(!1),"aria-label":"Close banner",children:"\u2715"})]}),t&&(0,a.jsxs)("div",{className:r.banner,role:"alert",children:[(0,a.jsx)("span",{className:r.bannerIcon,children:"\u2139\ufe0f"}),(0,a.jsx)("span",{className:r.bannerText,children:"Urdu translation coming soon \u2013 Full textbook will be available in \u0627\u0631\u062f\u0648"}),(0,a.jsx)("button",{className:r.closeBanner,onClick:()=>o(!1),"aria-label":"Close banner",children:"\u2715"})]})]})}},3249:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"module-3-nvidia-isaac/chapter-1-getting-started","title":"Chapter 1 - Getting Started with Isaac","description":"Introduction: Why NVIDIA Isaac?","source":"@site/docs/module-3-nvidia-isaac/chapter-1-getting-started.mdx","sourceDirName":"module-3-nvidia-isaac","slug":"/module-3-nvidia-isaac/chapter-1-getting-started","permalink":"/physical-ai-humanoid-textbook/docs/module-3-nvidia-isaac/chapter-1-getting-started","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"chapter-1-getting-started","title":"Chapter 1 - Getting Started with Isaac","sidebar_label":"Chapter 1: Getting Started"},"sidebar":"tutorialSidebar","previous":{"title":"Overview","permalink":"/physical-ai-humanoid-textbook/docs/module-3-nvidia-isaac/overview"},"next":{"title":"Overview","permalink":"/physical-ai-humanoid-textbook/docs/module-4-vision-language-action/overview"}}');var r=i(4848),a=i(8453),t=i(2781);const o={id:"chapter-1-getting-started",title:"Chapter 1 - Getting Started with Isaac",sidebar_label:"Chapter 1: Getting Started"},l="Chapter 1: Getting Started with NVIDIA Isaac",c={},d=[{value:"Introduction: Why NVIDIA Isaac?",id:"introduction-why-nvidia-isaac",level:2},{value:"The Isaac Ecosystem: Two Complementary Tools",id:"the-isaac-ecosystem-two-complementary-tools",level:2},{value:"1. Isaac Sim: The Virtual World",id:"1-isaac-sim-the-virtual-world",level:3},{value:"2. Isaac ROS: The Deployment Engine",id:"2-isaac-ros-the-deployment-engine",level:3},{value:"Isaac Sim in Action: Your First Simulation",id:"isaac-sim-in-action-your-first-simulation",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Example 1: Loading a Robot in Isaac Sim",id:"example-1-loading-a-robot-in-isaac-sim",level:3},{value:"Example 2: Custom World with ROS 2 Bridge",id:"example-2-custom-world-with-ros-2-bridge",level:3},{value:"Isaac ROS: Perception at Lightning Speed",id:"isaac-ros-perception-at-lightning-speed",level:2},{value:"Installation on Jetson or Ubuntu",id:"installation-on-jetson-or-ubuntu",level:3},{value:"Example: Real-Time Object Detection",id:"example-real-time-object-detection",level:3},{value:"Core Isaac ROS Packages",id:"core-isaac-ros-packages",level:2},{value:"1. Isaac ROS Image Segmentation",id:"1-isaac-ros-image-segmentation",level:3},{value:"2. Isaac ROS Depth Estimation",id:"2-isaac-ros-depth-estimation",level:3},{value:"3. Isaac ROS Visual SLAM",id:"3-isaac-ros-visual-slam",level:3},{value:"4. Isaac ROS Pose Estimation",id:"4-isaac-ros-pose-estimation",level:3},{value:"Bridging Sim-to-Real: Training in Isaac Sim, Deploying with Isaac ROS",id:"bridging-sim-to-real-training-in-isaac-sim-deploying-with-isaac-ros",level:2},{value:"The Sim-to-Real Gap Problem",id:"the-sim-to-real-gap-problem",level:3},{value:"Example: Training a Cube Detector",id:"example-training-a-cube-detector",level:3},{value:"Deploying to Jetson: The Edge AI Platform",id:"deploying-to-jetson-the-edge-ai-platform",level:2},{value:"Jetson Family Overview",id:"jetson-family-overview",level:3},{value:"Why Jetson for Humanoid Robots?",id:"why-jetson-for-humanoid-robots",level:3},{value:"Example: Running Isaac ROS on Jetson",id:"example-running-isaac-ros-on-jetson",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Hands-On Practice",id:"hands-on-practice",level:2},{value:"Exercise 1: Explore Isaac Sim Examples",id:"exercise-1-explore-isaac-sim-examples",level:3},{value:"Exercise 2: Calculate Performance Gain",id:"exercise-2-calculate-performance-gain",level:3},{value:"Exercise 3: Design a Sim-to-Real Pipeline",id:"exercise-3-design-a-sim-to-real-pipeline",level:3},{value:"Exercise 4: Jetson Selection",id:"exercise-4-jetson-selection",level:3},{value:"Common Mistakes Beginners Make",id:"common-mistakes-beginners-make",level:2},{value:"What&#39;s Next?",id:"whats-next",level:2}];function h(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"chapter-1-getting-started-with-nvidia-isaac",children:"Chapter 1: Getting Started with NVIDIA Isaac"})}),"\n",(0,r.jsx)(t.A,{}),"\n",(0,r.jsx)(n.h2,{id:"introduction-why-nvidia-isaac",children:"Introduction: Why NVIDIA Isaac?"}),"\n",(0,r.jsx)(n.p,{children:"Imagine you've built a beautiful ROS 2 system and created a digital twin in Gazebo. Everything works perfectly in simulation. But when you deploy to a real robot, you face these challenges:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Your vision algorithms are too slow"}),": Processing camera feeds at 2 FPS instead of the required 30 FPS"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Object detection fails in real lighting"}),": Your neural network trained on synthetic data doesn't recognize real-world objects"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"SLAM drifts in large spaces"}),": Your simultaneous localization and mapping breaks down in warehouses"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"No GPU acceleration"}),": Your Jetson or embedded GPU sits idle while the CPU struggles"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["This is where ",(0,r.jsx)(n.strong,{children:"NVIDIA Isaac"})," comes in. It's not a replacement for ROS 2\u2014it's a ",(0,r.jsx)(n.strong,{children:"supercharged enhancement"})," that brings:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim"}),": Photorealistic simulation with physics-accurate sensors and RTX ray tracing"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"}),": GPU-accelerated perception packages for deployment on real robots"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pretrained AI Models"}),": State-of-the-art models for object detection, pose estimation, and navigation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sim-to-Real Tools"}),": Domain randomization and synthetic data generation to bridge the simulation gap"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:'Think of Isaac as the "AI-Robot Brain" that makes your robot see, understand, and navigate the world at superhuman speed.'}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"the-isaac-ecosystem-two-complementary-tools",children:"The Isaac Ecosystem: Two Complementary Tools"}),"\n",(0,r.jsx)(n.p,{children:"NVIDIA Isaac consists of two main components that work together:"}),"\n",(0,r.jsx)(n.h3,{id:"1-isaac-sim-the-virtual-world",children:"1. Isaac Sim: The Virtual World"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim"})," is a simulation environment built on NVIDIA Omniverse, designed for training and testing robots."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Key Features:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Photorealistic Rendering"}),": RTX ray tracing for lifelike lighting, shadows, and reflections"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Physics-Accurate Sensors"}),": Camera distortion, LiDAR noise, depth sensor artifacts match real hardware"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synthetic Data Generation"}),": Automatically generate thousands of labeled training images"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 Integration"}),": Native bridges to publish sensor data and receive commands"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Domain Randomization"}),": Randomize textures, lighting, and object positions to improve real-world robustness"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"When to Use Isaac Sim:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Training vision models with synthetic data"}),"\n",(0,r.jsx)(n.li,{children:"Testing navigation in complex environments (warehouses, homes, outdoor spaces)"}),"\n",(0,r.jsx)(n.li,{children:"Prototyping new robot designs before building hardware"}),"\n",(0,r.jsx)(n.li,{children:"Generating datasets for rare scenarios (e.g., detecting fire extinguishers in emergency situations)"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"2-isaac-ros-the-deployment-engine",children:"2. Isaac ROS: The Deployment Engine"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"})," is a collection of GPU-accelerated ROS 2 packages for running perception and navigation on real robots."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Key Features:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU Acceleration"}),": Leverages CUDA and TensorRT to run models 10-100x faster than CPU"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Hardware-Optimized"}),": Designed for NVIDIA Jetson (Nano, Xavier, Orin) and discrete GPUs"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Standard ROS 2 Interface"}),": Drop-in replacements for existing ROS 2 perception nodes"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Pretrained Models"}),": Ready-to-use models for object detection (DetectNet), pose estimation (PoseNet), and depth estimation"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"When to Use Isaac ROS:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Deploying vision systems on resource-constrained robots"}),"\n",(0,r.jsx)(n.li,{children:"Real-time object detection and tracking (30+ FPS)"}),"\n",(0,r.jsx)(n.li,{children:"Visual SLAM (Simultaneous Localization and Mapping)"}),"\n",(0,r.jsx)(n.li,{children:"Obstacle avoidance with depth cameras"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Analogy:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim"})," is like a flight simulator for pilots\u2014safe, repeatable, and realistic."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"})," is like the autopilot system in a real airplane\u2014optimized for real-time performance."]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"isaac-sim-in-action-your-first-simulation",children:"Isaac Sim in Action: Your First Simulation"}),"\n",(0,r.jsx)(n.p,{children:"Let's set up Isaac Sim and run a simple robot simulation."}),"\n",(0,r.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"System Requirements:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"OS"}),": Ubuntu 20.04 or 22.04"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU"}),": NVIDIA RTX GPU (RTX 2070 or better recommended)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RAM"}),": 32 GB recommended"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Storage"}),": 50 GB free space"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Installation:"})}),"\n",(0,r.jsx)(n.p,{children:"Isaac Sim is distributed through NVIDIA Omniverse. Here's the quickest path:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:'# 1. Download Omniverse Launcher\n# Visit: https://www.nvidia.com/en-us/omniverse/download/\n# Download and install the launcher\n\n# 2. Install Isaac Sim from Omniverse Launcher\n# Open Launcher \u2192 Exchange \u2192 Search "Isaac Sim" \u2192 Install\n\n# 3. Install ROS 2 Bridge (if using ROS 2)\n# In Isaac Sim, go to: Window \u2192 Extensions \u2192 Search "ROS Bridge" \u2192 Enable\n'})}),"\n",(0,r.jsx)(n.h3,{id:"example-1-loading-a-robot-in-isaac-sim",children:"Example 1: Loading a Robot in Isaac Sim"}),"\n",(0,r.jsx)(n.p,{children:"Isaac Sim comes with pre-built robot models. Let's load a Franka Emika Panda robot arm."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Steps:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Launch Isaac Sim from Omniverse Launcher"}),"\n",(0,r.jsxs)(n.li,{children:["Go to: ",(0,r.jsx)(n.code,{children:"Isaac Examples \u2192 Manipulation \u2192 Pick and Place"})]}),"\n",(0,r.jsxs)(n.li,{children:["Press ",(0,r.jsx)(n.strong,{children:"Play"})," (bottom-left triangle button)"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"You'll see a robotic arm picking and placing objects with realistic physics!"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"What's Happening Under the Hood:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Isaac Sim loads the robot's URDF/USD (Universal Scene Description) file"}),"\n",(0,r.jsx)(n.li,{children:"PhysX engine calculates collisions, gravity, and joint dynamics"}),"\n",(0,r.jsx)(n.li,{children:"RTX renders photorealistic visuals at 60 FPS"}),"\n",(0,r.jsx)(n.li,{children:"The example script sends joint commands to the robot controller"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-2-custom-world-with-ros-2-bridge",children:"Example 2: Custom World with ROS 2 Bridge"}),"\n",(0,r.jsx)(n.p,{children:"Let's create a custom scene and connect it to ROS 2."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 1: Create a Simple World"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# custom_world.py - Run this in Isaac Sim\'s Script Editor\nfrom omni.isaac.kit import SimulationApp\n\n# Initialize Isaac Sim\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.objects import DynamicCuboid\nfrom omni.isaac.core.prims import RigidPrimView\nimport numpy as np\n\n# Create a world\nworld = World()\nworld.scene.add_default_ground_plane()\n\n# Add a cube that will fall due to gravity\ncube = world.scene.add(\n    DynamicCuboid(\n        prim_path="/World/Cube",\n        name="cube",\n        position=np.array([0, 0, 1.0]),  # 1 meter above ground\n        scale=np.array([0.2, 0.2, 0.2]),  # 20cm cube\n        color=np.array([1.0, 0, 0]),      # Red\n    )\n)\n\n# Reset and run simulation\nworld.reset()\n\nprint("Simulation ready! Press Play in the UI.")\nsimulation_app.update()\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 2: Enable ROS 2 Bridge"})}),"\n",(0,r.jsx)(n.p,{children:"In Isaac Sim UI:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Go to: ",(0,r.jsx)(n.code,{children:"Window \u2192 Extensions \u2192 Third Party \u2192 ROS Bridge"})]}),"\n",(0,r.jsx)(n.li,{children:"Enable the extension"}),"\n",(0,r.jsx)(n.li,{children:"Set ROS Domain ID to match your ROS 2 setup (usually 0)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 3: Publish Cube Position to ROS 2"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Add this to the previous script\nfrom omni.isaac.core.utils.extensions import enable_extension\nenable_extension("omni.isaac.ros2_bridge")\n\nimport rclpy\nfrom geometry_msgs.msg import Point\n\n# Initialize ROS 2 (outside the loop)\nrclpy.init()\n\n# Create a publisher (this would be in your ROS 2 node)\n# In practice, Isaac Sim\'s ROS bridge auto-publishes transforms\n# This is a simplified example\n\nwhile simulation_app.is_running():\n    world.step(render=True)  # Step physics and render\n\n    # Get cube position\n    cube_position, _ = cube.get_world_pose()\n\n    # In a real setup, this would be published via the ROS bridge\n    print(f"Cube position: {cube_position}")\n\nsimulation_app.close()\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"What You'll See:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"The cube falls due to gravity and bounces on the ground"}),"\n",(0,r.jsxs)(n.li,{children:["In ROS 2, you can subscribe to ",(0,r.jsx)(n.code,{children:"/cube/transform"})," to get its position in real-time"]}),"\n",(0,r.jsx)(n.li,{children:"This demonstrates how Isaac Sim bridges simulation to ROS 2 topics"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"isaac-ros-perception-at-lightning-speed",children:"Isaac ROS: Perception at Lightning Speed"}),"\n",(0,r.jsx)(n.p,{children:"Now let's deploy a vision system on a real robot using Isaac ROS."}),"\n",(0,r.jsx)(n.h3,{id:"installation-on-jetson-or-ubuntu",children:"Installation on Jetson or Ubuntu"}),"\n",(0,r.jsx)(n.p,{children:"Isaac ROS runs in Docker containers for reproducibility."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 1: Install Docker and NVIDIA Container Toolkit"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install Docker\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\n\n# Install NVIDIA Container Toolkit (for GPU access)\ndistribution=$(. /etc/os-release;echo $ID$VERSION_ID)\ncurl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -\ncurl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \\\n  sudo tee /etc/apt/sources.list.d/nvidia-docker.list\n\nsudo apt-get update\nsudo apt-get install -y nvidia-docker2\nsudo systemctl restart docker\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 2: Clone Isaac ROS Repositories"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"mkdir -p ~/workspaces/isaac_ros/src\ncd ~/workspaces/isaac_ros/src\n\n# Clone Isaac ROS common (required)\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\n\n# Clone a perception package (e.g., object detection)\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_object_detection.git\n\n# Clone depth perception package (example)\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_depth_perception.git\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 3: Build the Docker Container"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd ~/workspaces/isaac_ros\n\n# This script builds a Docker container with all dependencies\n./src/isaac_ros_common/scripts/run_dev.sh\n"})}),"\n",(0,r.jsx)(n.p,{children:"This may take 20-30 minutes on first run. It creates a container with:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"ROS 2 Humble"}),"\n",(0,r.jsx)(n.li,{children:"CUDA and TensorRT"}),"\n",(0,r.jsx)(n.li,{children:"Isaac ROS packages pre-built"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-real-time-object-detection",children:"Example: Real-Time Object Detection"}),"\n",(0,r.jsx)(n.p,{children:"Let's use Isaac ROS to detect objects from a camera feed."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Scenario:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"You have a robot with a USB camera"}),"\n",(0,r.jsx)(n.li,{children:"You want to detect people and objects at 30 FPS"}),"\n",(0,r.jsx)(n.li,{children:"You're running on a Jetson Orin Nano (8 GB RAM, 6-core ARM CPU, 1024-core GPU)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Launch File:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Inside the Isaac ROS Docker container\ncd /workspaces/isaac_ros\n\n# Launch object detection with a pre-trained model\nros2 launch isaac_ros_detectnet isaac_ros_detectnet.launch.py \\\n    model_name:=peoplenet \\\n    input_topic:=/camera/image_raw \\\n    output_topic:=/detections\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"What This Does:"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Subscribes to ",(0,r.jsx)(n.code,{children:"/camera/image_raw"})," (your USB camera feed)"]}),"\n",(0,r.jsxs)(n.li,{children:["Runs the ",(0,r.jsx)(n.code,{children:"PeopleNet"})," model (pretrained to detect people, bags, and faces) on the GPU"]}),"\n",(0,r.jsxs)(n.li,{children:["Publishes bounding boxes to ",(0,r.jsx)(n.code,{children:"/detections"})," at 30 FPS"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Visualize Detections:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# In another terminal (outside Docker)\nros2 run rqt_image_view rqt_image_view /detections_overlay\n"})}),"\n",(0,r.jsx)(n.p,{children:"You'll see bounding boxes drawn around detected people in real-time!"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Performance Comparison:"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Platform"}),(0,r.jsx)(n.th,{children:"CPU-Only (OpenCV DNN)"}),(0,r.jsx)(n.th,{children:"Isaac ROS (GPU)"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Orin Nano"}),(0,r.jsx)(n.td,{children:"3 FPS"}),(0,r.jsx)(n.td,{children:"30 FPS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson AGX Orin"}),(0,r.jsx)(n.td,{children:"5 FPS"}),(0,r.jsx)(n.td,{children:"60 FPS"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"RTX 4090 Desktop"}),(0,r.jsx)(n.td,{children:"12 FPS"}),(0,r.jsx)(n.td,{children:"120+ FPS"})]})]})]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Why the Speedup?"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TensorRT"}),": Optimizes the neural network for NVIDIA hardware"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Zero-Copy Memory"}),": Data stays on GPU; no CPU\u2194GPU transfers"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"INT8 Quantization"}),": Uses 8-bit integers instead of 32-bit floats (4x smaller, faster)"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"core-isaac-ros-packages",children:"Core Isaac ROS Packages"}),"\n",(0,r.jsx)(n.p,{children:"Isaac ROS provides modular packages for different perception tasks."}),"\n",(0,r.jsx)(n.h3,{id:"1-isaac-ros-image-segmentation",children:"1. Isaac ROS Image Segmentation"}),"\n",(0,r.jsx)(n.p,{children:"Segments images into semantic categories (road, sidewalk, car, person)."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use Case:"})," Autonomous navigation\u2014identify drivable surfaces vs. obstacles."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_unet isaac_ros_unet.launch.py \\\n    model_name:=peoplesemsegnet \\\n    input_topic:=/camera/image \\\n    output_topic:=/segmentation\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Each pixel labeled with a class (0=background, 1=person, 2=vehicle, etc.)"]}),"\n",(0,r.jsx)(n.h3,{id:"2-isaac-ros-depth-estimation",children:"2. Isaac ROS Depth Estimation"}),"\n",(0,r.jsx)(n.p,{children:"Generates depth maps from stereo cameras or monocular images (using AI)."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use Case:"})," Obstacle avoidance without expensive LiDAR."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_ess isaac_ros_ess.launch.py \\\n    left_image_topic:=/camera/left/image \\\n    right_image_topic:=/camera/right/image \\\n    depth_topic:=/depth\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Depth image where brightness = distance (darker = closer)"]}),"\n",(0,r.jsx)(n.h3,{id:"3-isaac-ros-visual-slam",children:"3. Isaac ROS Visual SLAM"}),"\n",(0,r.jsx)(n.p,{children:"Simultaneous Localization and Mapping using camera feeds."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use Case:"})," Indoor navigation without GPS."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_visual_slam isaac_ros_visual_slam.launch.py \\\n    camera_info_topic:=/camera/camera_info \\\n    image_topic:=/camera/image\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," Publishes ",(0,r.jsx)(n.code,{children:"/odom"})," (robot position) and ",(0,r.jsx)(n.code,{children:"/map"})," (3D point cloud)"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Advantages Over Traditional SLAM:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"GPU-Accelerated"}),": 10x faster feature extraction"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Robust to Motion Blur"}),": Deep learning handles challenging conditions"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Loop Closure Detection"}),": Recognizes previously visited places to correct drift"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"4-isaac-ros-pose-estimation",children:"4. Isaac ROS Pose Estimation"}),"\n",(0,r.jsx)(n.p,{children:"Detects human poses (skeleton keypoints) in real-time."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Use Case:"})," Human-robot interaction\u2014detect gestures, track people."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Example:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch isaac_ros_pose_estimation isaac_ros_pose_estimation.launch.py\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," 18 keypoints per person (head, shoulders, elbows, wrists, hips, knees, ankles)"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"bridging-sim-to-real-training-in-isaac-sim-deploying-with-isaac-ros",children:"Bridging Sim-to-Real: Training in Isaac Sim, Deploying with Isaac ROS"}),"\n",(0,r.jsxs)(n.p,{children:["One of Isaac's superpowers is the ",(0,r.jsx)(n.strong,{children:"sim-to-real pipeline"}),": train AI models in Isaac Sim, then deploy them on real robots with Isaac ROS."]}),"\n",(0,r.jsx)(n.h3,{id:"the-sim-to-real-gap-problem",children:"The Sim-to-Real Gap Problem"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"The Problem:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Models trained on synthetic data often fail in the real world"}),"\n",(0,r.jsx)(n.li,{children:"Lighting, textures, and sensor noise differ between simulation and reality"}),"\n",(0,r.jsxs)(n.li,{children:["This is called the ",(0,r.jsx)(n.strong,{children:"domain gap"})]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Isaac's Solution: Domain Randomization"})}),"\n",(0,r.jsx)(n.p,{children:"Randomize everything in simulation to make models robust:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lighting"}),": Vary brightness, color temperature, shadows"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Textures"}),": Swap floor patterns, wall colors"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Object Positions"}),": Randomly place objects in each training episode"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Camera Parameters"}),": Add lens distortion, motion blur, noise"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Result:"})," The model learns to ignore irrelevant details and focus on task-relevant features."]}),"\n",(0,r.jsx)(n.h3,{id:"example-training-a-cube-detector",children:"Example: Training a Cube Detector"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Goal:"})," Detect red cubes on a table (for a pick-and-place task)."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 1: Generate Synthetic Data in Isaac Sim"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# domain_randomization.py - Run in Isaac Sim\nfrom omni.isaac.core import World\nfrom omni.isaac.core.objects import DynamicCuboid\nfrom omni.replicator.core import random_colors, random_position\nimport omni.replicator.core as rep\n\nworld = World()\nworld.scene.add_default_ground_plane()\n\n# Create a table\ntable = world.scene.add(\n    DynamicCuboid(prim_path="/World/Table", position=[0.5, 0, 0.4],\n                  scale=[0.8, 1.2, 0.05], color=[0.5, 0.5, 0.5])\n)\n\n# Domain randomization: spawn cubes with random positions/colors\nwith rep.trigger.on_frame(num_frames=1000):\n    cube = rep.create.cube(\n        position=rep.distribution.uniform((-0.2, -0.3, 0.5), (0.2, 0.3, 0.6)),\n        scale=rep.distribution.uniform(0.05, 0.1),\n        color=rep.distribution.choice([\n            (1, 0, 0),      # Red (target)\n            (0, 1, 0),      # Green (distractor)\n            (0, 0, 1),      # Blue (distractor)\n        ])\n    )\n\n    # Randomize lighting\n    rep.modify.light(intensity=rep.distribution.uniform(500, 2000))\n\n# Render and save labeled images\nrep.run()\n'})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Output:"})," 1000 images with bounding box labels in COCO format."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 2: Train a Model"})}),"\n",(0,r.jsx)(n.p,{children:"Use NVIDIA TAO Toolkit (Transfer Learning Toolkit) to train a DetectNet model:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Train on synthetic data (uses transfer learning from pretrained weights)\ntao detectnet_v2 train \\\n    -e /workspace/specs/detectnet_train.txt \\\n    -r /workspace/output \\\n    -k nvidia_tao  # Encryption key\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Step 3: Deploy on Robot with Isaac ROS"})}),"\n",(0,r.jsx)(n.p,{children:"Convert the trained model to TensorRT and deploy:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Convert to TensorRT (optimized for Jetson)\ntao detectnet_v2 export \\\n    -m /workspace/output/weights/model.tlt \\\n    -k nvidia_tao \\\n    -o /workspace/models/cube_detector.engine\n\n# Launch Isaac ROS with your custom model\nros2 launch isaac_ros_detectnet isaac_ros_detectnet.launch.py \\\n    model_path:=/workspace/models/cube_detector.engine \\\n    input_topic:=/camera/image\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Result:"})," Real-time cube detection at 30 FPS on a Jetson, trained entirely in simulation!"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"deploying-to-jetson-the-edge-ai-platform",children:"Deploying to Jetson: The Edge AI Platform"}),"\n",(0,r.jsx)(n.p,{children:"NVIDIA Jetson is a family of embedded AI computers designed for robots."}),"\n",(0,r.jsx)(n.h3,{id:"jetson-family-overview",children:"Jetson Family Overview"}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Model"}),(0,r.jsx)(n.th,{children:"GPU Cores"}),(0,r.jsx)(n.th,{children:"RAM"}),(0,r.jsx)(n.th,{children:"Performance"}),(0,r.jsx)(n.th,{children:"Use Case"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Nano"}),(0,r.jsx)(n.td,{children:"128"}),(0,r.jsx)(n.td,{children:"4 GB"}),(0,r.jsx)(n.td,{children:"0.5 TFLOPS"}),(0,r.jsx)(n.td,{children:"Hobby robots, prototypes"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson Xavier NX"}),(0,r.jsx)(n.td,{children:"384"}),(0,r.jsx)(n.td,{children:"8 GB"}),(0,r.jsx)(n.td,{children:"21 TOPS"}),(0,r.jsx)(n.td,{children:"Drones, mobile robots"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Jetson AGX Orin"}),(0,r.jsx)(n.td,{children:"2048"}),(0,r.jsx)(n.td,{children:"64 GB"}),(0,r.jsx)(n.td,{children:"275 TOPS"}),(0,r.jsx)(n.td,{children:"Humanoids, autonomous vehicles"})]})]})]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"TOPS = Tera Operations Per Second"})," (for AI inference)"]}),"\n",(0,r.jsx)(n.h3,{id:"why-jetson-for-humanoid-robots",children:"Why Jetson for Humanoid Robots?"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Power Efficiency"}),": 15-60W (vs. 300W+ for desktop GPUs)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Compact Size"}),": Fits inside robot chassis"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Real-Time OS Support"}),": Runs real-time kernels for motor control"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS Optimized"}),": Pre-tuned for Jetson hardware"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"example-running-isaac-ros-on-jetson",children:"Example: Running Isaac ROS on Jetson"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Scenario:"})," Deploy visual SLAM on a mobile robot with a RealSense D435i camera."]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Hardware:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Jetson Orin Nano Developer Kit"}),"\n",(0,r.jsx)(n.li,{children:"Intel RealSense D435i (depth camera with IMU)"}),"\n",(0,r.jsx)(n.li,{children:"Mobile robot base with ROS 2"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Installation:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Flash JetPack OS (Ubuntu + CUDA + TensorRT)\n# Download SDK Manager: https://developer.nvidia.com/sdk-manager\n\n# Connect Jetson via USB and flash the OS\n# Select: JetPack 6.0 (includes ROS 2 Humble)\n\n# After flashing, SSH into Jetson\nssh nvidia@jetson.local\n\n# Install Isaac ROS (same Docker workflow as before)\ncd ~/workspaces/isaac_ros\n./src/isaac_ros_common/scripts/run_dev.sh\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Launch SLAM:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Inside Docker container\nros2 launch isaac_ros_visual_slam isaac_ros_visual_slam_realsense.launch.py\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Monitor Performance:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# In another terminal\njtop  # Jetson monitoring tool (install: sudo pip install jetson-stats)\n"})}),"\n",(0,r.jsx)(n.p,{children:"You'll see:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"GPU utilization: 80-95%"}),"\n",(0,r.jsx)(n.li,{children:"SLAM running at 30 FPS"}),"\n",(0,r.jsx)(n.li,{children:"Power consumption: ~10W"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim"})," is for training and testing robots in photorealistic virtual environments"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Isaac ROS"})," is for deploying GPU-accelerated perception on real robots (especially Jetson)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Domain randomization"})," bridges the sim-to-real gap by making models robust to variations"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"TensorRT"})," optimizes neural networks for 10-100x speedups on NVIDIA hardware"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Jetson"})," is the embedded AI platform for power-efficient, real-time robotics"]}),"\n",(0,r.jsxs)(n.li,{children:["Isaac integrates seamlessly with ",(0,r.jsx)(n.strong,{children:"ROS 2"}),"\u2014it's an enhancement, not a replacement"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"hands-on-practice",children:"Hands-On Practice"}),"\n",(0,r.jsx)(n.h3,{id:"exercise-1-explore-isaac-sim-examples",children:"Exercise 1: Explore Isaac Sim Examples"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Install Isaac Sim via Omniverse Launcher"}),"\n",(0,r.jsxs)(n.li,{children:["Run: ",(0,r.jsx)(n.code,{children:"Isaac Examples \u2192 Manipulation \u2192 Franka Pick and Place"})]}),"\n",(0,r.jsx)(n.li,{children:"Modify the script to change the cube's color to blue"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Hint:"})," Look for ",(0,r.jsx)(n.code,{children:"color"})," parameter in the example code."]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-2-calculate-performance-gain",children:"Exercise 2: Calculate Performance Gain"}),"\n",(0,r.jsx)(n.p,{children:"If a vision model runs at 5 FPS on a Jetson CPU and 50 FPS with Isaac ROS GPU acceleration:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"What is the speedup factor?"}),"\n",(0,r.jsx)(n.li,{children:"If the robot requires 30 FPS for real-time operation, is CPU-only viable?"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-3-design-a-sim-to-real-pipeline",children:"Exercise 3: Design a Sim-to-Real Pipeline"}),"\n",(0,r.jsx)(n.p,{children:"You want to train a robot to detect fire extinguishers in buildings."}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Question:"})," What would you randomize in Isaac Sim to make the model robust?"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Hint:"})," Think about lighting (day/night), backgrounds (walls, furniture), and fire extinguisher colors/shapes."]}),"\n",(0,r.jsx)(n.h3,{id:"exercise-4-jetson-selection",children:"Exercise 4: Jetson Selection"}),"\n",(0,r.jsx)(n.p,{children:"You're building a quadruped robot that needs to:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Run visual SLAM at 30 FPS"}),"\n",(0,r.jsx)(n.li,{children:"Detect objects with YOLO at 20 FPS"}),"\n",(0,r.jsx)(n.li,{children:"Operate for 2 hours on battery (power budget: 20W max)"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Question:"})," Which Jetson model would you choose? Why?"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"common-mistakes-beginners-make",children:"Common Mistakes Beginners Make"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Not using domain randomization"}),": Training on a single scene in Isaac Sim leads to overfitting"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Skipping TensorRT conversion"}),": Running PyTorch models directly on Jetson is 10x slower"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Ignoring sensor parameters"}),": Isaac Sim's default camera settings may not match your real camera (fix: calibrate and match intrinsics)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Overloading Jetson"}),": Running too many models simultaneously causes thermal throttling"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Forgetting ROS 2 Bridge setup"}),": Isaac Sim won't communicate with ROS 2 unless the bridge extension is enabled"]}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"whats-next",children:"What's Next?"}),"\n",(0,r.jsx)(n.p,{children:"In the next chapter, we'll:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Build a custom object detection model in Isaac Sim"}),"\n",(0,r.jsx)(n.li,{children:"Export it to TensorRT"}),"\n",(0,r.jsx)(n.li,{children:"Deploy it on a real robot with Isaac ROS"}),"\n",(0,r.jsx)(n.li,{children:"Integrate it with MoveIt 2 for pick-and-place tasks"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"You've now learned the foundation of NVIDIA Isaac. Next, we'll build a real-world AI robotics system!"}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Resources for Deeper Learning:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://docs.omniverse.nvidia.com/app_isaacsim/app_isaacsim/overview.html",children:"NVIDIA Isaac Sim Documentation"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://github.com/NVIDIA-ISAAC-ROS",children:"Isaac ROS GitHub"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://developer.nvidia.com/embedded/jetson",children:"Jetson Developer Zone"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"https://developer.nvidia.com/tao-toolkit",children:"TAO Toolkit (Training)"})}),"\n"]})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>o});var s=i(6540);const r={},a=s.createContext(r);function t(e){const n=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);